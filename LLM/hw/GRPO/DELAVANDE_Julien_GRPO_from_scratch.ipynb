{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "80517dbc",
      "metadata": {
        "id": "80517dbc"
      },
      "source": [
        "# GRPO Training project: teach an LLM to do additions, again"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DAEbh3jBadc7",
      "metadata": {
        "id": "DAEbh3jBadc7"
      },
      "source": [
        "In this notebook, you'll find:\n",
        "* A basic Transformer with basic tokenizer\n",
        "* A basic dataset for additions\n",
        "* A classical pre-trainer, minimizing cross entropy loss\n",
        "* A Vanilla GRPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MB8lj855LgHl",
      "metadata": {
        "id": "MB8lj855LgHl"
      },
      "source": [
        "You're not supposed to edit the existing code (you can if you want to...).\n",
        "You should implement one (or more) of the following:\n",
        "* GRPO with PPO (the `usual` one)\n",
        "* RLOO\n",
        "* ReMax\n",
        "* DPO\n",
        "* RAFT\n",
        "* your own RLHF method!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae993bb9",
      "metadata": {
        "id": "ae993bb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OzGh9ahKF17h",
      "metadata": {
        "id": "OzGh9ahKF17h"
      },
      "outputs": [],
      "source": [
        "num_digits = 3\n",
        "\n",
        "dataset_size = 64_000\n",
        "train_proportion = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabd151a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fabd151a",
        "outputId": "759ada76-0002-4cb5-a054-9f26368d4713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c054bed",
      "metadata": {
        "id": "6c054bed"
      },
      "source": [
        "## Step 1: Construct a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t6aC9uNeIR6C",
      "metadata": {
        "id": "t6aC9uNeIR6C"
      },
      "outputs": [],
      "source": [
        "pad_token=\"[PAD]\"\n",
        "eos_token=\"[EOS]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g2QiF-otFur3",
      "metadata": {
        "id": "g2QiF-otFur3"
      },
      "outputs": [],
      "source": [
        "class character_level_tokenizer:\n",
        "    \"\"\"\n",
        "    character-level\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n",
        "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
        "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
        "        self.ntokens = len(self.vocab)\n",
        "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
        "\n",
        "    def clean(self, text):\n",
        "        \"\"\"\n",
        "        removes all characters not in the vocabulary\n",
        "        \"\"\"\n",
        "        out = re.sub(self.pattern, \"\", text)\n",
        "        return out\n",
        "\n",
        "    def pre_tokenization(self, text):\n",
        "        \"\"\"\n",
        "        character-level\n",
        "        \"\"\"\n",
        "        return [c for c in text]\n",
        "\n",
        "    def encode(self, text):\n",
        "        text_list = self.pre_tokenization(self.clean(text))\n",
        "        return [self.token_to_id[c] for c in text_list]\n",
        "\n",
        "    def decode(self, token_list):\n",
        "        return \"\".join([self.id_to_token[x] for x in token_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QuCc6jF5F8hK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuCc6jF5F8hK",
        "outputId": "e1d407f5-433d-4446-d78e-b33825d3ad6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = character_level_tokenizer()\n",
        "ntokens = tokenizer.ntokens\n",
        "ntokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8FXW2K-1Jd-P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FXW2K-1Jd-P",
        "outputId": "b362fe28-a7ac-4f0d-9d17-808a2c3bfda4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1, 2, 10, 4, 2, 11], '12+42=')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"12 + 42 =\"\n",
        "inputs = tokenizer.encode(prompt)\n",
        "inputs, tokenizer.decode(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491af297",
      "metadata": {
        "id": "491af297"
      },
      "source": [
        "## Step 2: Create a dataset for arithmetic operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa90f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daa90f31",
        "outputId": "0b3f2608-e0cc-4542-8728-c89ba2b63bcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('702+620=', '1322')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sample_datapoint(num_digits = 3):\n",
        "    a_list = [random.randint(0, 9) for _ in range(num_digits)]\n",
        "    b_list = [random.randint(0, 9) for _ in range(num_digits)]\n",
        "    a_int = int(\"\".join([str(x) for x in a_list]))\n",
        "    b_int = int(\"\".join([str(x) for x in b_list]))\n",
        "    a_str = \"\".join([str(x) for x in a_list])\n",
        "    b_str = \"\".join([str(x) for x in b_list])\n",
        "    sum_int = a_int + b_int\n",
        "    return (a_str + \"+\" + b_str + \"=\", str(sum_int))\n",
        "\n",
        "sample_datapoint(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e861d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6e861d2",
        "outputId": "ad099c75-c23c-4e90-b056-0ad300442c8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('725+380=', '1105'),\n",
              " ('573+282=', '855'),\n",
              " ('224+846=', '1070'),\n",
              " ('368+009=', '377')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "for _ in range(dataset_size):\n",
        "    data.append(sample_datapoint(num_digits))\n",
        "data[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fee85050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee85050",
        "outputId": "e4c3b3e0-8550-460d-e794-5b0603995939"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(57600, 6400)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train = data[: int(train_proportion * dataset_size)]\n",
        "data_test = data[int(train_proportion * dataset_size):]\n",
        "\n",
        "len(data_train),len(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37200598",
      "metadata": {
        "id": "37200598"
      },
      "source": [
        "## Step 3: Construct a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91674239",
      "metadata": {
        "id": "91674239"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
        "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
        "        Here, we use sine and cosine functions of different frequencies.\n",
        "    .. math:\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb278ab",
      "metadata": {
        "id": "4eb278ab"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Transformer):\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__(d_model=ninp,\n",
        "                                               nhead=nhead,\n",
        "                                               dim_feedforward=nhid,\n",
        "                                               num_encoder_layers=nlayers)\n",
        "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.ninp = ninp\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.bias)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
        "\n",
        "    def forward(self, src):\n",
        "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "        self.src_mask = mask\n",
        "\n",
        "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output_enc = self.encoder(src, mask=self.src_mask)\n",
        "        output_dec = self.decoder(output_enc)\n",
        "        return F.log_softmax(output_dec, dim=-1), output_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d568cc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d568cc4",
        "outputId": "f82b125e-6408-4b65-ecfa-8fdbab0447a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-7): 8 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Linear(in_features=128, out_features=14, bias=True)\n",
              "  (input_emb): Embedding(14, 128)\n",
              "  (pos_encoder): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = TransformerModel(ntoken = ntokens,\n",
        "                         ninp = 128,\n",
        "                         nhead = 16,\n",
        "                         nhid = 64,\n",
        "                         nlayers = 8)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6PmJSo95N4C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6PmJSo95N4C",
        "outputId": "67525394-ea82-418a-ca57-2cff9a4a437e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 668942\n"
          ]
        }
      ],
      "source": [
        "print(\"number of parameters: {}\".format(sum([x.numel() for x in model.parameters()])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e35d113",
      "metadata": {
        "id": "2e35d113"
      },
      "source": [
        "### Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2f06e0",
      "metadata": {
        "id": "8f2f06e0"
      },
      "outputs": [],
      "source": [
        "def generate(model, prompts, new_tokens = 5, mode = \"greedy\", num_samples = 1, temperature = 0.8):\n",
        "    input_tensor = torch.repeat_interleave(prompts, repeats = num_samples, dim = 1).to(device)\n",
        "    # (prompt_length, batch_size * num_samples)\n",
        "    for _ in range(new_tokens):\n",
        "        output, _ = model(input_tensor) # (prompt_length, batch_size * num_samples, ntokens)\n",
        "        logits = output[-1,:,:] # (batch_size * num_samples, ntokens)\n",
        "        if mode == \"greedy\":\n",
        "            tokens = torch.argmax(logits, -1).view((1,-1)) # (1, batch_size * num_samples)\n",
        "        else: # mode == \"sampling\"\n",
        "            logits /= temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            tokens = torch.multinomial(probs, num_samples = 1).view((1,-1)) # (1, batch_size * num_samples)\n",
        "        input_tensor = torch.cat((input_tensor, tokens), 0)\n",
        "    return input_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76d1b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76d1b19",
        "outputId": "8cfb67de-c595-479b-8f1c-53261385c0bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 2, 10,  3, 11,  9,  9,  9,  9,  9]], device='cuda:0'), '2+3=99999')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"2+3=\"\n",
        "prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
        "output = generate(model, prompt_tensor).view((1,-1))\n",
        "output, tokenizer.decode(output[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00954ddc",
      "metadata": {
        "id": "00954ddc"
      },
      "outputs": [],
      "source": [
        "def pad(token_list, type_list = \"prompts\"):\n",
        "    max_length = max([len(x) for x in token_list])\n",
        "    out = []\n",
        "    for x in token_list:\n",
        "        if type_list == \"prompts\":\n",
        "            out.append([tokenizer.token_to_id[pad_token]] * (max_length - len(x)) + x)\n",
        "        if type_list == \"answers\":\n",
        "            out.append(x + [tokenizer.token_to_id[eos_token]] + [tokenizer.token_to_id[pad_token]] * (max_length - len(x)))\n",
        "    return out, max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c84beab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c84beab",
        "outputId": "9dc831bf-cb06-41dd-e653-b4be27ff73a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['[PAD][PAD]1+1=', '21+35='], ['2[EOS][PAD]', '56[EOS]'])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts = [tokenizer.encode(\"1+1=\"), tokenizer.encode(\"21+35=\")]\n",
        "answers = [tokenizer.encode(\"2\"), tokenizer.encode(\"56\")]\n",
        "padded_prompts, _ = pad(prompts, \"prompts\")\n",
        "padded_answers, _ = pad(answers, \"answers\")\n",
        "padded_prompts, padded_answers\n",
        "[tokenizer.decode(p) for p in padded_prompts], [tokenizer.decode(p) for p in padded_answers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264f9227",
      "metadata": {
        "id": "264f9227"
      },
      "outputs": [],
      "source": [
        "def get_batch(split, i, batch_size):\n",
        "    data = data_train if split == 'train' else data_test\n",
        "\n",
        "    prompts = [data[i][0] for i in range(i, i + batch_size)]\n",
        "    encoded_prompts = [tokenizer.encode(prompt) for prompt in prompts]\n",
        "    padded_prompts, prompt_length = pad(encoded_prompts, \"prompts\")\n",
        "\n",
        "    answers = [data[i][1] for i in range(i, i + batch_size)]\n",
        "    encoded_answers = [tokenizer.encode(answer) for answer in answers]\n",
        "    padded_answers, answers_length = pad(encoded_answers, \"answers\")\n",
        "\n",
        "    X = torch.stack([torch.tensor(x) for x in padded_prompts], 1)\n",
        "    Y = torch.stack([torch.tensor(x) for x in padded_answers], 1)\n",
        "    return X, Y, prompt_length, answers_length, prompts, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e281ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e281ad",
        "outputId": "857620cd-c0eb-4906-c437-aaedb6a7d177"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([8, 16]), torch.Size([5, 16]), 8, 4, '775+390=', '1165')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y, prompt_length, answers_length, prompts, answers = get_batch(\"train\", 43, 16)\n",
        "X.shape, Y.shape, prompt_length, answers_length, prompts[0], answers[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113e1fd1",
      "metadata": {
        "id": "113e1fd1"
      },
      "source": [
        "## Step 4: Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KfmcSdPwp3K6",
      "metadata": {
        "id": "KfmcSdPwp3K6"
      },
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfcd10a",
      "metadata": {
        "id": "1cfcd10a"
      },
      "outputs": [],
      "source": [
        "def evaluate(batch_size = batch_size):\n",
        "    # Turn on evaluation mode disables dropout.\n",
        "    model.eval()\n",
        "    correct = 0.\n",
        "    with torch.no_grad():\n",
        "        for batch, i in enumerate(range(0, len(data_test) - 1, batch_size)):\n",
        "            prompts, target_answers, prompt_length, answers_length, _, _ = get_batch(\"test\", i, batch_size)\n",
        "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
        "            target_answers = target_answers.to(device) # (answers_length + 1, batch_size)\n",
        "            output = generate(model, prompts, answers_length + 1) # (prompt_length + answers_length + 1, batch_size)\n",
        "            answers_tokens = output[prompt_length:, :] # (answers_length + 1, batch_size), contains tokens\n",
        "            equality_test = answers_tokens == target_answers # (answers_length + 1, batch_size), contains boolean values\n",
        "            correct += torch.all(equality_test, axis=0).float().sum()\n",
        "        accuracy = correct / len(data_test)\n",
        "    return accuracy.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac335b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac335b05",
        "outputId": "c85feb17-e6a3-4dd2-939f-45a8bdb00828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c54061a",
      "metadata": {
        "id": "4c54061a"
      },
      "source": [
        "## Step 5: Train the model, classical approach"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b827e567",
      "metadata": {
        "id": "b827e567"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b140ba3",
      "metadata": {
        "id": "5b140ba3"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "batch_size = 16\n",
        "learning_rate = 8e-4\n",
        "\n",
        "reporting_per_epoch = 5\n",
        "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
        "assert(log_interval % batch_size == 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3638a75d",
      "metadata": {
        "id": "3638a75d"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_test_accuracy = None\n",
        "    test_accuracy = evaluate()\n",
        "    print('-' * 89)\n",
        "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
        "    print('-' * 89)\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        total_loss = 0.\n",
        "        start_time = time.time()\n",
        "        for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
        "            prompts, target_answers, prompt_length, answers_length, _, _ = get_batch(\"train\", i, batch_size)\n",
        "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
        "            target_answers = target_answers.to(device) # (answers_length + 1, batch_size)\n",
        "            input_tensor = torch.cat((prompts, target_answers), 0) # (prompt_length + answers_length + 1, batch_size)\n",
        "            model.zero_grad()\n",
        "            output, _ = model(input_tensor) # (prompt_length + answers_length + 1, batch_size, ntokens)\n",
        "            output_answers = output[prompt_length-1:-1,:,:].reshape(-1, ntokens) # ((answers_length + 1) * batch_size, ntokens)\n",
        "            target_answers = target_answers.view(-1)\n",
        "            loss = F.cross_entropy(output_answers, target_answers)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % log_interval == 0 and batch > 0:\n",
        "                cur_loss = total_loss / log_interval\n",
        "                elapsed = time.time() - start_time\n",
        "                print('| {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.2f} | perplexity {:8.2f}'.format(batch, len(data_train) // batch_size,\n",
        "                                                                                                            elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "                total_loss = 0\n",
        "                start_time = time.time()\n",
        "        test_accuracy = evaluate()\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the test accuracy is the best we've seen so far.\n",
        "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
        "            with open(\"arithmetic.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_test_accuracy = test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2a8490",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4e2a8490",
        "outputId": "549efa68-638c-41f6-9ea9-e0ac7bbf1443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| initialisation | test accuracy  0.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch  1.10 | loss  0.01 | perplexity     1.01\n",
            "|  1200/ 3600 batches | ms/batch  1.12 | loss  0.00 | perplexity     1.00\n",
            "|  1800/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  2400/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  3000/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 72.81s | test accuracy  1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  1200/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  1800/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  2400/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  3000/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 72.45s | test accuracy  1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch  1.06 | loss  0.00 | perplexity     1.00\n",
            "|  1200/ 3600 batches | ms/batch  1.15 | loss  0.00 | perplexity     1.00\n",
            "|  1800/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  2400/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  3000/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 72.95s | test accuracy  1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch  1.04 | loss  0.00 | perplexity     1.00\n",
            "|  1200/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  1800/ 3600 batches | ms/batch  1.08 | loss  0.00 | perplexity     1.00\n",
            "|  2400/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  3000/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 72.01s | test accuracy  1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch  1.05 | loss  0.00 | perplexity     1.00\n",
            "|  1200/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "|  1800/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  2400/ 3600 batches | ms/batch  1.10 | loss  0.00 | perplexity     1.00\n",
            "|  3000/ 3600 batches | ms/batch  1.09 | loss  0.00 | perplexity     1.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 75.39s | test accuracy  1.00\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-2da0ffaf5447>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-d8b508b9335c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtarget_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d9d440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56d9d440",
        "outputId": "612b21dd-06ce-4527-c9a5-cb845407aba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "592+554=1144[EOS]\t actual result: 1146\n",
            "852+172=1022[EOS]\t actual result: 1024\n",
            "760+734=1494[EOS]\t actual result: 1494\n",
            "295+549=844[EOS]\t actual result: 844\n",
            "158+181=334[EOS]\t actual result: 339\n",
            "995+086=1084[EOS]\t actual result: 1081\n",
            "195+339=534[EOS]\t actual result: 534\n",
            "526+962=1484[EOS]\t actual result: 1488\n",
            "044+318=364[EOS]\t actual result: 362\n",
            "885+887=1774[EOS]\t actual result: 1772\n",
            "207+852=1052[EOS]\t actual result: 1059\n",
            "250+793=1044[EOS]\t actual result: 1043\n",
            "625+900=1522[EOS]\t actual result: 1525\n",
            "331+957=1282[EOS]\t actual result: 1288\n",
            "545+039=582[EOS]\t actual result: 584\n",
            "685+742=1424[EOS]\t actual result: 1427\n",
            "371+900=1274[EOS]\t actual result: 1271\n",
            "592+954=1544[EOS]\t actual result: 1546\n",
            "546+266=812[EOS]\t actual result: 812\n",
            "375+894=1264[EOS]\t actual result: 1269\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "for i in range(20):\n",
        "    prompt, answers = data_test[i]\n",
        "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
        "    output = generate(model, prompt_tensor, len(answers) + 1).view((1,-1))\n",
        "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfa4c591",
      "metadata": {
        "id": "cfa4c591"
      },
      "source": [
        "## Step 4 bis: Vanilla GRPO training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff83f72",
      "metadata": {
        "id": "aff83f72"
      },
      "source": [
        "### Custom reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c548bf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c548bf7",
        "outputId": "e0a359c3-c0a7-469a-85b4-a8137572d3fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 0.0)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def accuracy_reward(output, answer):\n",
        "    pattern = r\"\\[EOS\\]\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    pattern = r\"(\\[PAD\\])*$\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    return 1. if output == answer else 0.\n",
        "\n",
        "accuracy_reward(\"123[EOS][PAD][PAD]\", \"123\"), accuracy_reward(\"123\", \"124\"),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f02762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1f02762",
        "outputId": "ad753cb9-ff52-4285-eb89-a51d5574f07f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0.008064516129032258)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def distance_accuracy_reward(output, answer):\n",
        "    pattern = r\"\\[EOS\\]\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    pattern = r\"(\\[PAD\\])*$\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    int_output = int(output)\n",
        "    int_answer = int(answer)\n",
        "    return abs(int_output - int_answer) / max(int_output, int_answer)\n",
        "\n",
        "distance_accuracy_reward(\"123[EOS]\", \"123\"), distance_accuracy_reward(\"123[PAD]\", \"124\"),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42a0d70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42a0d70",
        "outputId": "ba657de3-95b7-46ff-97be-1fa6489649ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 1.0)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def digit_accuracy_reward(output, answer):\n",
        "    pattern = r\"\\[EOS\\]\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    pattern = r\"(\\[PAD\\])*$\"\n",
        "    output = re.sub(pattern, \"\", output)\n",
        "    return sum(c1 == c2 for (c1,c2) in zip(output, answer)) / max(len(output), len(answer))\n",
        "\n",
        "digit_accuracy_reward(\"123[EOS][PAD][PAD]\", \"123\"), digit_accuracy_reward(\"123[EOS]\", \"123\"),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41603b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a41603b2",
        "outputId": "f839d7dc-dcf8-4d8a-d9ea-aaf323a881f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 1.0, 0.0)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def reward_format(output):\n",
        "    pattern = r\"\\d+\\[EOS\\](\\[PAD\\])*$\"\n",
        "    return 1. if bool(re.match(pattern, output)) else 0.\n",
        "\n",
        "reward_format(\"123[EOS][PAD][PAD]\"), reward_format(\"123[EOS]\"), reward_format(\"123\"),"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4482e411",
      "metadata": {
        "id": "4482e411"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf764cb0",
      "metadata": {
        "id": "cf764cb0"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "num_samples = 16\n",
        "temperature = .8\n",
        "\n",
        "reporting_per_epoch = 5\n",
        "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
        "assert(log_interval % batch_size == 0)\n",
        "\n",
        "reward_fun = digit_accuracy_reward\n",
        "reward_format = reward_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15cdced",
      "metadata": {
        "id": "f15cdced"
      },
      "outputs": [],
      "source": [
        "def compute_rewards(text_outputs, answers):\n",
        "    repeated_answers = [answer for answer in answers for _ in range(num_samples)]\n",
        "    rewards = torch.tensor(\n",
        "        [0.2 * reward_format(output) + 0.8 * reward_fun(output, answer)\n",
        "         for output, answer in zip(text_outputs, repeated_answers)],\n",
        "        dtype=torch.float32,\n",
        "        device=device\n",
        "    )\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22be0d4",
      "metadata": {
        "id": "e22be0d4"
      },
      "outputs": [],
      "source": [
        "def calculate_grpo_advantages(rewards):\n",
        "    # reshape rewards to group by prompt\n",
        "    # compute mean and standard deviation for each prompt group\n",
        "    mean_rewards = rewards.view(-1, num_samples).mean(dim=1)\n",
        "    std_rewards = rewards.view(-1, num_samples).std(dim=1)\n",
        "    # expand the means and stds to match the original flat rewards tensor shape\n",
        "    mean_rewards = mean_rewards.repeat_interleave(num_samples, dim=0)\n",
        "    std_rewards = std_rewards.repeat_interleave(num_samples, dim=0)\n",
        "    # normalize rewards to get advantages\n",
        "    advantages = (rewards - mean_rewards) / (std_rewards + 1e-5)\n",
        "    return advantages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faac5c99",
      "metadata": {
        "id": "faac5c99"
      },
      "outputs": [],
      "source": [
        "def compute_log_probs(model, outputs, prompt_length):\n",
        "    logits, _ = model(outputs)\n",
        "    # logits.shape = (prompt_length + answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "\n",
        "    # we only need the log probabilities for the new tokens\n",
        "    # this introduces a shift: the logits for a position are the predictions for the next token\n",
        "    logits = logits[prompt_length-1:-1, :, :]\n",
        "    # logits.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "\n",
        "    # convert raw logits into log probabilities along the vocabulary axis\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    # log_probs.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "    return log_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2612214",
      "metadata": {
        "id": "b2612214"
      },
      "outputs": [],
      "source": [
        "def compute_loss(advantages, log_probs, responses):\n",
        "    # reshape responses from (answers_length + 1, batch_size * num_samples)\n",
        "    # to (answers_length + 1, batch_size * num_samples, 1) for gathering\n",
        "    responses = responses.unsqueeze(-1)\n",
        "    # log_probs.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "    # responses.shape = (answers_length + 1, batch_size * num_samples)\n",
        "    # gather the log probability for each token in responses\n",
        "    selected_log_probs = log_probs.gather(dim=-1, index=responses)\n",
        "    # remove the extra last dimension to get back to shape (answers_length + 1, batch_size * num_samples).\n",
        "    selected_log_probs = selected_log_probs.squeeze(-1)\n",
        "\n",
        "    # normalize\n",
        "    selected_log_probs = (selected_log_probs - selected_log_probs.mean(-1, keepdim=True)) / (selected_log_probs.std(-1, keepdim=True) + 1e-5)\n",
        "\n",
        "    # advantages.shape = (batch_size * num_samples)\n",
        "    # we use the same advantages for all tokens in the response\n",
        "    loss = -(advantages.unsqueeze(dim=0) * selected_log_probs).mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824ca075",
      "metadata": {
        "id": "824ca075"
      },
      "outputs": [],
      "source": [
        "def train_vanilla_GRPO(verbose = False):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_test_accuracy = None\n",
        "    test_accuracy = evaluate()\n",
        "    print('-' * 89)\n",
        "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
        "    print('-' * 89)\n",
        "\n",
        "    # switch eval for train model (enables dropout)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        start_time = time.time()\n",
        "        for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
        "\n",
        "            # get a batch of prompts and answers\n",
        "            prompts, _, prompt_length, answers_length, questions, answers = get_batch(\"train\", i, batch_size)\n",
        "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
        "\n",
        "            # generate samples for each prompt\n",
        "            outputs = generate(model,\n",
        "                               prompts,\n",
        "                               new_tokens = answers_length + 1,\n",
        "                               mode = \"sampling\",\n",
        "                               num_samples = num_samples,\n",
        "                               temperature = temperature)\n",
        "            # outputs.shape = (prompt_length + answers_length + 1, batch_size * num_samples)\n",
        "            text_outputs = [tokenizer.decode(outputs[prompt_length:, i].tolist())\n",
        "                            for i in range(outputs.size(1))]\n",
        "\n",
        "            # compute rewards\n",
        "            rewards = compute_rewards(text_outputs, answers)\n",
        "\n",
        "            # compute advantages\n",
        "            advantages = calculate_grpo_advantages(rewards)\n",
        "\n",
        "            # compute log probabilities\n",
        "\n",
        "            log_probs = compute_log_probs(model, outputs, prompt_length)\n",
        "\n",
        "            # compute loss\n",
        "            responses = outputs[prompt_length:, :]\n",
        "            loss = compute_loss(advantages, log_probs, responses)\n",
        "\n",
        "            # optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if i % log_interval == 0 and batch > 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print('| {:5d}/{:5d} batches | ms/batch {:5.2f}'.format(batch, len(data_train) // batch_size, elapsed))\n",
        "                if verbose:\n",
        "                    print(\"\\nquestion:\", questions[0],\n",
        "                      \"\\nanswer\", answers[0],\n",
        "                      \"\\noutput:\", text_outputs[:num_samples],\n",
        "                      \"\\nreward:\", rewards[:num_samples],\n",
        "                      \"\\nadvantage:\", advantages[:num_samples], \"\\n\")\n",
        "\n",
        "                start_time = time.time()\n",
        "        test_accuracy = evaluate()\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the test accuracy is the best we've seen so far.\n",
        "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
        "            with open(\"arithmetic_vanilla_GRPO.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_test_accuracy = test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02716ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "b02716ff",
        "outputId": "d3ae59c3-1d5f-4e40-e428-097a04b4edb1",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| initialisation | test accuracy  0.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 832.02\n",
            "|  1200/ 3600 batches | ms/batch 815.49\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_vanilla_GRPO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[41], line 47\u001b[0m, in \u001b[0;36mtrain_vanilla_GRPO\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss(advantages, log_probs, responses)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# optimize\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32md:\\Documents\\Scolaires\\MVA\\venv\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Documents\\Scolaires\\MVA\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Documents\\Scolaires\\MVA\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_vanilla_GRPO(verbose = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fd99fd",
      "metadata": {},
      "source": [
        "## GRPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46a4815",
      "metadata": {
        "id": "e46a4815"
      },
      "outputs": [],
      "source": [
        "def compute_loss_grpo(advantages, log_probs, log_probs_old, log_probs_ref, responses, beta, eps):\n",
        "    # reshape responses from (answers_length + 1, batch_size * num_samples)\n",
        "    # to (answers_length + 1, batch_size * num_samples, 1) for gathering\n",
        "    responses = responses.unsqueeze(-1)\n",
        "    # log_probs.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "    # responses.shape = (answers_length + 1, batch_size * num_samples)\n",
        "    # gather the log probability for each token in responses\n",
        "    selected_log_probs = log_probs.gather(dim=-1, index=responses)\n",
        "    selected_log_probs_old = log_probs_old.gather(dim=-1, index=responses)\n",
        "    selected_log_probs_ref = log_probs_ref.gather(dim=-1, index=responses)\n",
        "\n",
        "\n",
        "    # remove the extra last dimension to get back to shape (answers_length + 1, batch_size * num_samples).\n",
        "    selected_log_probs = selected_log_probs.squeeze(-1) # (answers_length + 1, batch_size * num_samples)\n",
        "    selected_log_probs_old = selected_log_probs_old.squeeze(-1) # (answers_length + 1, batch_size * num_samples)\n",
        "    selected_log_probs_ref = selected_log_probs_ref.squeeze(-1) # (answers_length + 1, batch_size * num_samples)\n",
        "\n",
        "    selected_log_probs = torch.log(torch.clamp(selected_log_probs, min=1e-10))\n",
        "    selected_log_probs_old = torch.log(torch.clamp(selected_log_probs_old, min=1e-10))\n",
        "    selected_log_probs_ref = torch.log(torch.clamp(selected_log_probs_ref, min=1e-10))\n",
        "\n",
        "    # normalize\n",
        "    #selected_log_probs = (selected_log_probs - selected_log_probs.mean(-1, keepdim=True)) / (selected_log_probs.std(-1, keepdim=True) + 1e-5)\n",
        "\n",
        "    # advantages.shape = (batch_size * num_samples)\n",
        "    # we use the same advantages for all tokens in the response\n",
        "    #loss = -(advantages.unsqueeze(dim=0) * selected_log_probs).mean()\n",
        "    advantages = advantages.unsqueeze(dim=0) # (1, batch_size * num_samples)\n",
        "    div_KL = (selected_log_probs_ref - selected_log_probs).exp() - selected_log_probs_ref + selected_log_probs - 1\n",
        "\n",
        "    pi_norm  = (selected_log_probs - selected_log_probs_old).exp()\n",
        "    loss_oi = - (torch.min(pi_norm * advantages, torch.clamp(pi_norm, 1 - eps, 1 + eps) * advantages) - beta * div_KL) # (answers_length + 1, batch_size * num_samples)\n",
        "    loss = loss_oi.mean(dim=0).mean() # (1)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a9d316",
      "metadata": {
        "id": "b4a9d316"
      },
      "outputs": [],
      "source": [
        "verbose = True\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "num_samples = 16\n",
        "temperature = .8\n",
        "\n",
        "reporting_per_epoch = 5\n",
        "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
        "assert(log_interval % batch_size == 0)\n",
        "\n",
        "reward_fun = digit_accuracy_reward\n",
        "reward_format = reward_format\n",
        "\n",
        "mu = 1 # number of optimization steps (iterations per batch)\n",
        "beta = 0.04 # penalty factor\n",
        "eps = 0.8 # clip\n",
        "\n",
        "#paper\n",
        "lr = 1e-6\n",
        "beta = 0.04\n",
        "num_samples_paper = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40db5dab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40db5dab",
        "outputId": "ab402ebf-2e5c-47c2-d847-e34019a106f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| initialisation | test accuracy  0.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 84.51\n",
            "\n",
            "loss: -1.7462298274040222e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1162[EOS]', '586[EOS][PAD]', '527[EOS][PAD]', '119[EOS][PAD]', '474[EOS][PAD]', '1107[EOS]', '1108[EOS]', '5999[EOS]', '329[EOS][PAD]', '308[EOS][PAD]', '538[EOS][PAD]', '421[EOS][PAD]', '6177[EOS]', '419[EOS]9', '380[EOS][PAD]', '1171[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.4667, 0.4667, 0.2000, 0.2000, 0.4000, 0.4667,\n",
            "        0.2000, 0.4667, 0.4667, 0.2000, 0.4000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.8428, -0.8428, -0.8428,  1.2318,  1.2318, -0.8428, -0.8428,  0.7132,\n",
            "         1.2318, -0.8428,  1.2318,  1.2318, -0.8428,  0.7132, -0.8428, -0.8428],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 84.43\n",
            "\n",
            "loss: -4.0512531995773315e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['129[EOS][PAD]', '47[EOS]1[EOS]', '414[EOS][PAD]', '351[EOS][PAD]', '11[EOS][PAD][PAD]', '415[EOS][PAD]', '115[EOS][PAD]', '9836[EOS]', '4976[EOS]', '316[EOS][PAD]', '1[PAD]1[EOS][PAD]', '1117[EOS]', '334[EOS][PAD]', '217[EOS][PAD]', '1866[EOS]', '466[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.0000, 0.2000, 0.4667, 0.2000, 0.4667, 0.4667, 0.2000, 0.2000,\n",
            "        0.4667, 0.0000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.1499, -1.6499, -0.4500,  1.1499, -0.4500,  1.1499,  1.1499, -0.4500,\n",
            "        -0.4500,  1.1499, -1.6499, -0.4500,  1.1499, -0.4500, -0.4500, -0.4500],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 83.82\n",
            "\n",
            "loss: -3.166496753692627e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['537[EOS][PAD]', '1937[EOS]', '9219[EOS]', '698[EOS][PAD]', '1196[EOS]', '928[EOS][PAD]', '1150[EOS]', '499[EOS][PAD]', '552[EOS][PAD]', '613[EOS][PAD]', '719[EOS][PAD]', '1182[EOS]', '496[EOS][PAD]', '422[EOS][PAD]', '1178[EOS]', '1109[EOS]'] \n",
            "reward: tensor([0.7333, 0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.2000, 0.4667, 0.4667,\n",
            "        0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 2.7102, -0.5937, -0.5937, -0.5937,  0.6453, -0.5937, -0.5937,  1.0583,\n",
            "         1.0583, -0.5937,  1.0583, -0.5937, -0.5937, -0.5937, -0.5937, -0.5937],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 83.94\n",
            "\n",
            "loss: 7.450580596923828e-09 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['72[EOS][PAD][PAD]', '114[EOS]0', '73[EOS][PAD][PAD]', '1776[EOS]', '118[EOS][PAD]', '1578[EOS]', '7776[PAD]', '866[EOS][PAD]', '1008[EOS]', '1258[EOS]', '1025[EOS]', '7976[EOS]', '110[EOS][EOS]', '198[EOS][PAD]', '189[EOS][PAD]', '1168[EOS]'] \n",
            "reward: tensor([0.2000, 0.0000, 0.2000, 0.2000, 0.4667, 0.2000, 0.0000, 0.4667, 0.4000,\n",
            "        0.2000, 0.4000, 0.2000, 0.0000, 0.4667, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.2323, -1.4713, -0.2323, -0.2323,  1.4196, -0.2323, -1.4713,  1.4196,\n",
            "         1.0066, -0.2323,  1.0066, -0.2323, -1.4713,  1.4196, -0.2323, -0.2323],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 83.37\n",
            "\n",
            "loss: -6.752088665962219e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['118[EOS]9', '110[EOS][EOS]', '1098[EOS]', '1107[EOS]', '10096', '1122[EOS]', '098[EOS][EOS]', '1101[EOS]', '1298[EOS]', '117[EOS]2', '1217[EOS]', '1201[EOS]', '1119[EOS]', '122[EOS]4', '1217[EOS]', '1210[EOS]'] \n",
            "reward: tensor([0.2000, 0.4000, 0.6000, 0.6000, 0.3200, 0.4000, 0.0000, 0.6000, 0.8000,\n",
            "        0.2000, 0.6000, 0.8000, 0.4000, 0.4000, 0.6000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.2255, -0.3177,  0.5901,  0.5901, -0.6809, -0.3177, -2.1333,  0.5901,\n",
            "         1.4979, -1.2255,  0.5901,  1.4979, -0.3177, -0.3177,  0.5901,  0.5901],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 513.35s | test accuracy  0.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 84.10\n",
            "\n",
            "loss: -4.190951585769653e-09 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['516[EOS][PAD]', '1189[EOS]', '106[EOS]1', '1120[EOS]', '13[EOS][PAD][PAD]', '095[EOS][EOS]', '61[EOS][PAD]1', '149[EOS][PAD]', '582[EOS][PAD]', '444[EOS][PAD]', '639[EOS][PAD]', '110[EOS]0', '6148[EOS]', '1189[EOS]', '511[EOS]1', '4418[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.0000, 0.2000, 0.4667, 0.0000, 0.0000, 0.4667, 0.2000,\n",
            "        0.4667, 0.7333, 0.0000, 0.2000, 0.2000, 0.0000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.1521, -0.1521, -1.0650, -0.1521,  1.0650, -1.0650, -1.0650,  1.0650,\n",
            "        -0.1521,  1.0650,  2.2821, -1.0650, -0.1521, -0.1521, -1.0650,  0.7607],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.32\n",
            "\n",
            "loss: -1.7462298274040222e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['312[EOS][PAD]', '982[EOS][EOS]', '316[EOS]1', '198[EOS][PAD]', '316[EOS][PAD]', '999[EOS][PAD]', '416[EOS][PAD]', '428[EOS][PAD]', '147[EOS][PAD]', '114[EOS][PAD]', '926[EOS][PAD]', '1134[EOS]', '418[EOS][PAD]', '419[EOS][PAD]', '1004[EOS]', '395[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.0000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667, 0.2000,\n",
            "        0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.9949, -1.5965, -0.4859, -0.4859,  0.9949, -0.4859, -0.4859,  0.9949,\n",
            "        -0.4859, -0.4859,  0.9949, -0.4859, -0.4859, -0.4859, -0.4859,  2.4757],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 84.22\n",
            "\n",
            "loss: 7.450580596923828e-09 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['1104[EOS]', '109[EOS][PAD]', '54[EOS][PAD][PAD]', '1190[EOS]', '798[EOS][PAD]', '1197[EOS]', '549[EOS][PAD]', '599[EOS][PAD]', '518[EOS][PAD]', '621[EOS]1', '1399[EOS]', '6157[EOS]', '927[EOS][PAD]', '1198[EOS]', '1906[EOS]', '779[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.4667, 0.4000, 0.2000, 0.4000, 0.7333, 0.7333, 0.4667,\n",
            "        0.0000, 0.6000, 0.2000, 0.2000, 0.4000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.8906,  0.4048,  0.4048,  0.0810, -0.8906,  0.0810,  1.7003,  1.7003,\n",
            "         0.4048, -1.8622,  1.0525, -0.8906, -0.8906,  0.0810, -0.8906,  0.4048],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 83.98\n",
            "\n",
            "loss: -2.8405338525772095e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['806[EOS][PAD]', '1307[EOS]', '136[EOS][PAD]', '1474[EOS]', '100[EOS][PAD]', '1132[EOS]', '130[EOS][PAD]', '100[EOS][PAD]', '1107[EOS]', '1939[EOS]', '7112[EOS]', '1167[EOS]', '109[EOS][PAD]', '118[EOS][EOS]', '920[EOS][PAD]', '80[EOS][EOS][PAD]'] \n",
            "reward: tensor([0.7333, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.4667, 0.2667, 0.2000, 0.5333],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 2.5231, -0.6431, -0.6431, -0.6431,  0.9400, -0.6431, -0.6431,  0.9400,\n",
            "        -0.6431, -0.6431, -0.6431, -0.6431,  0.9400, -0.2474, -0.6431,  1.3357],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.10\n",
            "\n",
            "loss: -9.313225746154785e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1182[EOS]', '1620[EOS]', '1170[EOS]', '1968[EOS]', '1266[EOS]', '120[EOS][PAD]', '1289[EOS]', '1025[EOS]', '1134[EOS]', '121[EOS][PAD]', '19948', '112[EOS]1', '1109[EOS]', '1114[EOS]', '298[EOS][PAD]', '1198[EOS]'] \n",
            "reward: tensor([0.4000, 0.4000, 0.4000, 0.6000, 0.6000, 0.8000, 0.6000, 0.4000, 0.4000,\n",
            "        0.6000, 0.1600, 0.2000, 0.6000, 0.4000, 0.2000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3354, -0.3354, -0.3354,  0.7826,  0.7826,  1.9006,  0.7826, -0.3354,\n",
            "        -0.3354,  0.7826, -1.6770, -1.4534,  0.7826, -0.3354, -1.4534,  0.7826],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 514.23s | test accuracy  0.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 83.91\n",
            "\n",
            "loss: 2.0721927285194397e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['142[EOS]1', '118[EOS][PAD]', '1413[EOS]', '431[EOS][PAD]', '1175[EOS]', '410[EOS][EOS]', '116[EOS]2', '1106[EOS]', '438[EOS][PAD]', '517[EOS][PAD]', '4027[EOS]', '314[EOS][PAD]', '131[EOS][PAD]', '458[EOS][PAD]', '11891', '54[EOS][PAD]0'] \n",
            "reward: tensor([0.0000, 0.2000, 0.2000, 0.7333, 0.2000, 0.2667, 0.0000, 0.2000, 0.7333,\n",
            "        0.2000, 0.4000, 0.2000, 0.4667, 0.4667, 0.0000, 0.0000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.1239e+00, -2.8096e-01, -2.8096e-01,  1.9667e+00, -2.8096e-01,\n",
            "         1.2560e-07, -1.1239e+00, -2.8096e-01,  1.9667e+00, -2.8096e-01,\n",
            "         5.6193e-01, -2.8096e-01,  8.4289e-01,  8.4289e-01, -1.1239e+00,\n",
            "        -1.1239e+00], device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 85.19\n",
            "\n",
            "loss: -1.4435499906539917e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['301[EOS][PAD]', '2963[EOS]', '1964[EOS]', '317[EOS][PAD]', '2167[EOS]', '266[EOS][PAD]', '483[EOS][PAD]', '133[EOS][PAD]', '118[EOS][PAD]', '217[EOS][PAD]', '914[EOS][PAD]', '338[EOS][PAD]', '6354[EOS]', '424[EOS][EOS]', '42[EOS][PAD][PAD]', '32666'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.2000, 0.4667, 0.4000, 0.2667, 0.4667, 0.3200],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.4814, -0.7653, -0.7653,  1.4814, -0.7653, -0.7653, -0.7653, -0.7653,\n",
            "        -0.7653, -0.7653, -0.7653,  1.4814,  0.9198, -0.2036,  1.4814,  0.2457],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 84.37\n",
            "\n",
            "loss: -5.2852556109428406e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['389[EOS][PAD]', '1120[EOS]', '400[EOS][PAD]', '103[EOS][EOS]', '1175[EOS]', '638[EOS][PAD]', '10867', '689[EOS][PAD]', '0598[EOS]', '511[EOS][PAD]', '1098[EOS]', '630[EOS]9', '439[EOS][PAD]', '102[EOS][PAD]', '1101[EOS]', '1190[EOS]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.0000, 0.2000, 0.4667, 0.0000, 0.4667, 0.4000,\n",
            "        0.4667, 0.4000, 0.2000, 0.7333, 0.2000, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.7933, -0.5789, -0.5789, -1.6081, -0.5789,  0.7933, -1.6081,  0.7933,\n",
            "         0.4503,  0.7933,  0.4503, -0.5789,  2.1656, -0.5789, -0.5789,  0.4503],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 84.65\n",
            "\n",
            "loss: -1.3737007975578308e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['711[EOS][PAD]', '810[EOS][PAD]', '777[EOS][PAD]', '1181[EOS]', '1337[EOS]', '8918[EOS]', '121[EOS][PAD]', '1727[EOS]', '7074[EOS]', '879[EOS][PAD]', '1000[EOS]', '819[EOS][PAD]', '404[EOS][PAD]', '778[EOS][PAD]', '1111[EOS]', '713[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.2000, 0.4000, 0.2000, 0.4000, 0.2000, 0.2000, 0.4000,\n",
            "        0.4667, 0.4000, 0.4667, 0.4667, 0.4667, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.0741,  1.0741, -1.0741,  0.5370, -1.0741,  0.5370, -1.0741, -1.0741,\n",
            "         0.5370,  1.0741,  0.5370,  1.0741,  1.0741,  1.0741, -1.0741, -1.0741],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.49\n",
            "\n",
            "loss: 4.190951585769653e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1518[EOS]', '1116[EOS]', '1129[EOS]', '14774', '401[EOS]9', '1228[EOS]', '1189[EOS]', '1181[EOS]', '1115[EOS]', '1959[EOS]', '1209[PAD]', '100[EOS][EOS]', '11083', '1018[EOS]', '11029', '1216[EOS]'] \n",
            "reward: tensor([0.6000, 0.4000, 0.4000, 0.1600, 0.0000, 0.8000, 0.4000, 0.4000, 0.4000,\n",
            "        0.4000, 0.6000, 0.4000, 0.4800, 0.6000, 0.3200, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.8771, -0.1860, -0.1860, -1.4618, -2.3123,  1.9402, -0.1860, -0.1860,\n",
            "        -0.1860, -0.1860,  0.8771, -0.1860,  0.2392,  0.8771, -0.6113,  0.8771],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 517.11s | test accuracy  0.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 85.91\n",
            "\n",
            "loss: 2.514570951461792e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1029[EOS]', '1100[EOS]', '1961[EOS]', '148[EOS][PAD]', '[PAD]42[EOS][PAD]', '1336[EOS]', '118[EOS][PAD]', '1126[EOS]', '327[EOS][PAD]', '1170[EOS]', '125[EOS][PAD]', '114[EOS][PAD]', '1117[EOS]', '118[EOS]1', '1288[EOS]', '1349[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.4000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -1.9363,  1.9363,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.9363,  0.0000,  1.9363],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 84.52\n",
            "\n",
            "loss: -1.4435499906539917e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['496[EOS][PAD]', '417[EOS][PAD]', '1373[EOS]', '1302[EOS]', '116[EOS][PAD]', '326[EOS][PAD]', '2169[EOS]', '2737[EOS]', '136[EOS][PAD]', '400[EOS][PAD]', '416[EOS][PAD]', '1135[EOS]', '3127[EOS]', '1063[EOS]', '161[EOS][PAD]', '1152[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4057, -0.4057, -0.4057, -0.4057, -0.4057,  3.3039, -0.4057, -0.4057,\n",
            "        -0.4057, -0.4057, -0.4057, -0.4057,  0.9854, -0.4057, -0.4057,  0.9854],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 85.07\n",
            "\n",
            "loss: -2.60770320892334e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['5272[EOS]', '5949[EOS]', '627[EOS][PAD]', '614[EOS][PAD]', '417[EOS][PAD]', '439[EOS][PAD]', '1329[PAD]', '599[EOS][PAD]', '594[EOS][PAD]', '1016[EOS]', '5781[PAD]', '1198[EOS]', '415[EOS][PAD]', '1121[EOS]', '1139[EOS]', '799[EOS][PAD]'] \n",
            "reward: tensor([0.4000, 0.4000, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.7333, 0.4667,\n",
            "        0.2000, 0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.3329,  0.3329, -0.7324, -0.7324, -0.7324,  2.1085, -0.7324,  2.1085,\n",
            "         0.6880, -0.7324, -0.7324,  0.3329, -0.7324, -0.7324, -0.7324,  0.6880],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 83.76\n",
            "\n",
            "loss: -4.284083843231201e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['1076[EOS]', '760[EOS][PAD]', '669[EOS][PAD]', '1097[EOS]', '174[EOS][PAD]', '1178[EOS]', '1499[EOS]', '1[PAD]10[EOS]', '7969[EOS]', '156[EOS][PAD]', '114[EOS][PAD]', '701[EOS][PAD]', '8458[EOS]', '1068[EOS]', '101[EOS][PAD]', '126[EOS][PAD]'] \n",
            "reward: tensor([0.4000, 0.2000, 0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.0000, 0.2000,\n",
            "        0.2000, 0.2000, 0.4667, 0.4000, 0.4000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.9774, -0.5360, -0.5360,  0.9774, -0.5360, -0.5360, -0.5360, -2.0493,\n",
            "        -0.5360, -0.5360, -0.5360,  1.4818,  0.9774,  0.9774,  1.4818, -0.5360],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.66\n",
            "\n",
            "loss: -4.1211023926734924e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1189[EOS]', '1198[EOS]', '1298[EOS]', '1101[EOS]', '122[EOS][EOS]', '1289[EOS]', '1164[EOS]', '115[EOS][PAD]', '1048[EOS]', '101[EOS]9', '1412[EOS]', '1118[EOS]', '1005[EOS]', '946[EOS]2', '110[EOS][PAD]', '139[EOS]6'] \n",
            "reward: tensor([0.4000, 0.6000, 0.8000, 0.6000, 0.4000, 0.6000, 0.4000, 0.4000, 0.6000,\n",
            "        0.2000, 0.4000, 0.6000, 0.6000, 0.0000, 0.6000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3080,  0.6777,  1.6633,  0.6777, -0.3080,  0.6777, -0.3080, -0.3080,\n",
            "         0.6777, -1.2937, -0.3080,  0.6777,  0.6777, -2.2794,  0.6777, -1.2937],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 517.57s | test accuracy  0.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 83.62\n",
            "\n",
            "loss: -5.3783878684043884e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['989[EOS][PAD]', '1182[EOS]', '523[EOS][PAD]', '438[EOS][PAD]', '110[EOS][PAD]', '1906[EOS]', '192[EOS][PAD]', '599[EOS][PAD]', '114[EOS][PAD]', '1159[EOS]', '1113[EOS]', '410[EOS][PAD]', '1143[EOS]', '418[EOS][PAD]', '408[EOS][PAD]', '1123[EOS]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.7333, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000,\n",
            "        0.2000, 0.2000, 0.4667, 0.2000, 0.4667, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.8940, -0.6953, -0.6953,  2.4834, -0.6953, -0.6953, -0.6953,  0.8940,\n",
            "        -0.6953, -0.6953, -0.6953,  0.8940, -0.6953,  0.8940,  0.8940, -0.6953],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.90\n",
            "\n",
            "loss: -3.306195139884949e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['284[EOS][PAD]', '2465[EOS]', '46[EOS][PAD][PAD]', '1129[EOS]', '1153[EOS]', '131[EOS][PAD]', '314[EOS][PAD]', '1044[EOS]', '41[EOS][PAD][PAD]', '353[EOS][PAD]', '217[EOS][PAD]', '156[EOS][PAD]', '7436[EOS]', '5087[EOS]', '1163[EOS]', '116[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.4667, 0.2000, 0.2000,\n",
            "        0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4604, -0.4604, -0.4604, -0.4604,  1.5487, -0.4604,  2.2184, -0.4604,\n",
            "        -0.4604,  2.2184, -0.4604, -0.4604, -0.4604, -0.4604, -0.4604, -0.4604],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 83.20\n",
            "\n",
            "loss: -1.4202669262886047e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['644[EOS][PAD]', '1571[EOS]', '1819[EOS]', '581[EOS][PAD]', '188[EOS][PAD]', '110[EOS][PAD]', '4389[EOS]', '1599[EOS]', '0180[EOS]', '4268[EOS]', '438[EOS][PAD]', '822[EOS][PAD]', '114[EOS][PAD]', '6477[EOS]', '1029[EOS]', '711[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4000, 0.4000, 0.2000,\n",
            "        0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5515, -0.5515, -0.5515,  1.9697, -0.5515, -0.5515,  1.3394,  1.3394,\n",
            "        -0.5515, -0.5515,  1.9697, -0.5515, -0.5515, -0.5515, -0.5515, -0.5515],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 83.28\n",
            "\n",
            "loss: -1.257285475730896e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['918[EOS][PAD]', '1658[EOS]', '1129[EOS]', '1180[EOS]', '[EOS][PAD]50[EOS]', '1760[EOS]', '807[EOS][PAD]', '989[EOS][PAD]', '77[EOS][PAD]9', '868[EOS][PAD]', '749[EOS][PAD]', '617[EOS][PAD]', '1158[EOS]', '80[EOS][PAD][PAD]', '4128[EOS]', '254[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.4000, 0.0000, 0.2000, 0.7333, 0.2000, 0.0000,\n",
            "        0.7333, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.6744, -0.4323, -0.4323,  0.3977, -1.2623, -0.4323,  1.7811, -0.4323,\n",
            "        -1.2623,  1.7811, -0.4323, -0.4323, -0.4323,  1.7811, -0.4323, -0.4323],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 83.04\n",
            "\n",
            "loss: -6.05359673500061e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1198[EOS]', '132[EOS]1', '111[EOS][PAD]', '1108[EOS]', '1935[EOS]', '11889', '1107[EOS]', '100[EOS][PAD]', '1015[EOS]', '1124[EOS]', '11044', '1492[EOS]', '1099[EOS]', '1400[EOS]', '1180[EOS]', '1190[EOS]'] \n",
            "reward: tensor([0.6000, 0.2000, 0.4000, 0.8000, 0.4000, 0.3200, 0.6000, 0.6000, 0.4000,\n",
            "        0.4000, 0.3200, 0.4000, 0.4000, 0.6000, 0.4000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.9963, -1.7056, -0.3546,  2.3473, -0.3546, -0.8950,  0.9963,  0.9963,\n",
            "        -0.3546, -0.3546, -0.8950, -0.3546, -0.3546,  0.9963, -0.3546, -0.3546],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 510.65s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 83.07\n",
            "\n",
            "loss: -1.0710209608078003e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['429[EOS][PAD]', '1101[EOS]', '1179[EOS]', '1930[EOS]', '501[EOS][PAD]', '433[EOS][PAD]', '1238[EOS]', '1230[EOS]', '41757', '609[EOS][PAD]', '42[EOS][PAD][EOS]', '4207[EOS]', '450[EOS][PAD]', '1104[EOS]', '8882[EOS]', '112[EOS][PAD]'] \n",
            "reward: tensor([0.7333, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.2000, 0.1600,\n",
            "        0.4667, 0.2667, 0.4000, 0.4667, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 2.1917, -0.5969, -0.5969, -0.5969, -0.5969,  2.1917, -0.5969, -0.5969,\n",
            "        -0.8061,  0.7974, -0.2484,  0.4488,  0.7974, -0.5969, -0.5969, -0.5969],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.25\n",
            "\n",
            "loss: 9.313225746154785e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['208[EOS][PAD]', '315[EOS][PAD]', '18[EOS][PAD][PAD]', '414[EOS][PAD]', '137[EOS][PAD]', '411[EOS][PAD]', '227[EOS][PAD]', '011[EOS][PAD]', '355[EOS][PAD]', '4167[EOS]', '290[EOS][PAD]', '21[PAD][PAD][PAD]', '426[EOS][PAD]', '1348[EOS]', '520[EOS][PAD]', '486[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.7333, 0.2000, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.7333,\n",
            "        0.2000, 0.2000, 0.0000, 0.4667, 0.2000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5009,  2.0638, -0.5009, -0.5009, -0.5009, -0.5009,  0.7814, -0.5009,\n",
            "         2.0638, -0.5009, -0.5009, -1.4627,  0.7814, -0.5009,  0.7814, -0.5009],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 83.08\n",
            "\n",
            "loss: -5.634501576423645e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['589[EOS][PAD]', '110[EOS][PAD]', '1190[EOS]', '1159[EOS]', '416[EOS]1', '601[EOS][PAD]', '629[EOS][PAD]', '1119[EOS]', '7879[EOS]', '542[EOS][PAD]', '532[EOS][PAD]', '1209[EOS]', '522[EOS][PAD]', '49[EOS][PAD][PAD]', '1161[EOS]', '526[EOS][PAD]'] \n",
            "reward: tensor([0.7333, 0.2000, 0.4000, 0.2000, 0.0000, 0.2000, 0.4667, 0.2000, 0.2000,\n",
            "        0.4667, 0.7333, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.9231, -0.6410,  0.3205, -0.6410, -1.6026, -0.6410,  0.6410, -0.6410,\n",
            "        -0.6410,  0.6410,  1.9231, -0.6410,  0.6410, -0.6410, -0.6410,  0.6410],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 82.42\n",
            "\n",
            "loss: 8.381903171539307e-09 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['878[EOS][PAD]', '109[EOS][PAD]', '785[EOS][PAD]', '770[EOS][PAD]', '1304[EOS]', '807[EOS][PAD]', '763[EOS][PAD]', '1013[EOS]', '718[EOS][PAD]', '1001[EOS]', '876[EOS][PAD]', '1150[EOS]', '1909[EOS]', '899[EOS][PAD]', '7158[EOS]', '1881[EOS]'] \n",
            "reward: tensor([0.7333, 0.4667, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.4000, 0.4667,\n",
            "        0.4000, 0.4667, 0.2000, 0.2000, 0.4667, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.9728,  0.5216, -0.9297, -0.9297, -0.9297,  1.9728, -0.9297,  0.1587,\n",
            "         0.5216,  0.1587,  0.5216, -0.9297, -0.9297,  0.5216, -0.9297,  0.1587],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 83.23\n",
            "\n",
            "loss: 6.833579391241074e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1006[EOS]', '11149', '119[EOS][PAD]', '1998[EOS]', '1189[EOS]', '1109[EOS]', '1148[EOS]', '1219[EOS]', '10819', '1282[EOS]', '1267[EOS]', '191[EOS][PAD]', '1191[EOS]', '110[EOS][PAD]', '1989[EOS]', '1291[EOS]'] \n",
            "reward: tensor([0.6000, 0.1600, 0.4000, 0.6000, 0.4000, 0.6000, 0.6000, 0.6000, 0.1600,\n",
            "        0.6000, 0.6000, 0.4000, 0.4000, 0.6000, 0.4000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.7519, -2.0636, -0.5279,  0.7519, -0.5279,  0.7519,  0.7519,  0.7519,\n",
            "        -2.0636,  0.7519,  0.7519, -0.5279, -0.5279,  0.7519, -0.5279,  0.7519],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 509.06s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 85.27\n",
            "\n",
            "loss: -1.3969838619232178e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1028[EOS]', '113[EOS][PAD]', '5172[EOS]', '344[EOS][PAD]', '782[EOS][PAD]', '1178[EOS]', '430[EOS][PAD]', '1944[EOS]', '1991[EOS]', '1069[EOS]', '681[EOS][PAD]', '000[EOS][PAD]', '42[EOS]9[EOS]', '1126[EOS]', '139[EOS][PAD]', '1182[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.4000,\n",
            "        0.2000, 0.2000, 0.2000, 0.5333, 0.2000, 0.7333, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5175, -0.5175, -0.5175, -0.5175, -0.5175, -0.5175,  2.2426, -0.5175,\n",
            "         0.5175, -0.5175, -0.5175, -0.5175,  1.2076, -0.5175,  2.2426, -0.5175],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.72\n",
            "\n",
            "loss: -1.0244548320770264e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['181[EOS][PAD]', '97[EOS][PAD][PAD]', '155[EOS][PAD]', '1138[EOS]', '297[EOS][PAD]', '186[EOS][PAD]', '1134[EOS]', '144[EOS][PAD]', '388[EOS][PAD]', '213[EOS][PAD]', '614[EOS][PAD]', '190[EOS][PAD]', '419[EOS][PAD]', '425[EOS]1', '367[EOS][PAD]', '1164[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.4667,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.4000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5541, -0.5541,  1.8099, -0.5541, -0.5541, -0.5541, -0.5541, -0.5541,\n",
            "         1.8099, -0.5541, -0.5541, -0.5541, -0.5541,  1.2189,  1.8099, -0.5541],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 83.60\n",
            "\n",
            "loss: -3.026798367500305e-09 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['459[EOS][PAD]', '118[EOS][PAD]', '1179[EOS]', '1109[EOS]', '1179[EOS]', '918[EOS][PAD]', '691[EOS][PAD]', '117[EOS][PAD]', '681[EOS][PAD]', '638[EOS][PAD]', '589[EOS][PAD]', '680[EOS][PAD]', '1100[EOS]', '532[EOS][PAD]', '1273[EOS]', '1189[EOS]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.4667, 0.7333, 0.2000, 0.2000, 0.7333, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.8695, -0.5217, -0.5217, -0.5217, -0.5217, -0.5217, -0.5217, -0.5217,\n",
            "        -0.5217,  0.8695,  2.2606, -0.5217, -0.5217,  2.2606, -0.5217, -0.5217],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 85.14\n",
            "\n",
            "loss: -1.3504177331924438e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['7157[EOS]', '765[EOS][PAD]', '1060[EOS]', '616[EOS][PAD]', '747[PAD][PAD]', '811[EOS][PAD]', '1383[EOS]', '111[EOS][PAD]', '1441[EOS]', '1179[EOS]', '887[EOS][PAD]', '116[EOS][PAD]', '801[EOS][PAD]', '678[EOS][PAD]', '1787[EOS]', '1117[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.4000, 0.2000, 0.0000, 0.4667, 0.4000, 0.2000, 0.2000,\n",
            "        0.2000, 0.4667, 0.2000, 0.7333, 0.4667, 0.4000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.6120, -0.6120,  0.5178, -0.6120, -1.7418,  0.8944,  0.5178, -0.6120,\n",
            "        -0.6120, -0.6120,  0.8944, -0.6120,  2.4008,  0.8944,  0.5178, -0.6120],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 86.11\n",
            "\n",
            "loss: -1.83936208486557e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1209[EOS]', '1189[EOS]', '1129[EOS]', '1198[EOS]', '35458', '12549', '1181[EOS]', '1195[EOS]', '1901[EOS]', '120[EOS][PAD]', '1308[EOS]', '1129[EOS]', '1029[EOS]', '1338[EOS]', '1297[EOS]', '1199[EOS]'] \n",
            "reward: tensor([0.8000, 0.4000, 0.4000, 0.6000, 0.0000, 0.3200, 0.4000, 0.4000, 0.6000,\n",
            "        0.8000, 0.8000, 0.4000, 0.4000, 0.6000, 0.6000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.4518, -0.4522, -0.4522,  0.4998, -2.3561, -0.8330, -0.4522, -0.4522,\n",
            "         0.4998,  1.4518,  1.4518, -0.4522, -0.4522,  0.4998,  0.4998, -0.4522],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 522.74s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 87.84\n",
            "\n",
            "loss: 2.2584572434425354e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1150[EOS]', '1928[EOS]', '1041[EOS]', '495[EOS][PAD]', '168[EOS][EOS]', '118[EOS][PAD]', '446[EOS][PAD]', '5899[EOS]', '149[EOS][PAD]', '113[EOS][PAD]', '1139[EOS]', '1191[EOS]', '582[EOS][PAD]', '440[EOS][PAD]', '417[EOS][PAD]', '11[EOS]10'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.4667, 0.0000, 0.2000, 0.4667, 0.4000, 0.4667,\n",
            "        0.2000, 0.2000, 0.4000, 0.2000, 0.4667, 0.4667, 0.0000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5075, -0.5075, -0.5075,  1.1164, -1.7254, -0.5075,  1.1164,  0.7105,\n",
            "         1.1164, -0.5075, -0.5075,  0.7105, -0.5075,  1.1164,  1.1164, -1.7254],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 89.29\n",
            "\n",
            "loss: 5.820766091346741e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['417[EOS][PAD]', '117[EOS][PAD]', '172[EOS][PAD]', '401[EOS][EOS]', '417[EOS][PAD]', '527[EOS][PAD]', '186[EOS][PAD]', '144[EOS][PAD]', '301[EOS][PAD]', '1967[EOS]', '128[EOS][PAD]', '91[PAD][PAD][PAD]', '108[EOS][PAD]', '3556[EOS]', '326[EOS][PAD]', '131[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.0000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667,\n",
            "        0.2000, 0.4667, 0.0000, 0.2000, 0.6000, 0.7333, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4077, -0.4077, -0.4077, -1.3861, -0.4077,  0.8969, -0.4077, -0.4077,\n",
            "         0.8969, -0.4077,  0.8969, -1.3861, -0.4077,  1.5492,  2.2015, -0.4077],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 88.47\n",
            "\n",
            "loss: -1.955777406692505e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['4314[EOS]', '114[EOS][PAD]', '1190[EOS]', '1180[EOS]', '11916', '1286[EOS]', '617[EOS][PAD]', '11199', '119[EOS]1', '6198[EOS]', '1179[EOS]', '5081[EOS]', '142[EOS][PAD]', '111[EOS][PAD]', '1140[EOS]', '113[EOS][PAD]'] \n",
            "reward: tensor([0.4000, 0.2000, 0.4000, 0.2000, 0.1600, 0.2000, 0.2000, 0.0000, 0.2000,\n",
            "        0.4000, 0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.4978, -0.3177,  1.4978, -0.3177, -0.6808, -0.3177, -0.3177, -2.1332,\n",
            "        -0.3177,  1.4978, -0.3177,  1.4978, -0.3177, -0.3177, -0.3177, -0.3177],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 88.86\n",
            "\n",
            "loss: -7.450580596923828e-09 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['208[EOS][PAD]', '11708', '1907[EOS]', '703[EOS][PAD]', '89[EOS]9[EOS]', '617[EOS][PAD]', '1167[EOS]', '718[EOS][PAD]', '1575[EOS]', '1183[EOS]', '807[EOS][PAD]', '414[EOS][PAD]', '71[EOS][PAD]1', '114[EOS][PAD]', '882[EOS][PAD]', '1479[EOS]'] \n",
            "reward: tensor([0.7333, 0.0000, 0.2000, 0.4667, 0.2667, 0.2000, 0.2000, 0.4667, 0.2000,\n",
            "        0.4000, 0.7333, 0.2000, 0.0000, 0.2000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.9413, -1.4084, -0.4948,  0.7232, -0.1903, -0.4948, -0.4948,  0.7232,\n",
            "        -0.4948,  0.4187,  1.9413, -0.4948, -1.4084, -0.4948,  0.7232, -0.4948],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 88.53\n",
            "\n",
            "loss: -2.561137080192566e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1108[EOS]', '1357[EOS]', '1111[EOS]', '114[EOS][EOS]', '1205[EOS]', '1172[EOS]', '1118[EOS]', '1009[EOS]', '1509[EOS]', '120[EOS][PAD]', '1172[EOS]', '1118[EOS]', '11157', '131[EOS][PAD]', '1087[EOS]', '1219[EOS]'] \n",
            "reward: tensor([0.8000, 0.4000, 0.4000, 0.2000, 0.8000, 0.4000, 0.6000, 0.6000, 0.6000,\n",
            "        0.8000, 0.4000, 0.6000, 0.1600, 0.4000, 0.4000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.4697, -0.5575, -0.5575, -1.5710,  1.4697, -0.5575,  0.4561,  0.4561,\n",
            "         0.4561,  1.4697, -0.5575,  0.4561, -1.7737, -0.5575, -0.5575,  0.4561],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 541.53s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 87.92\n",
            "\n",
            "loss: -1.3969838619232178e-09 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1117[EOS]', '1127[EOS]', '1110[EOS]', '2753[EOS]', '649[EOS][PAD]', '469[EOS][PAD]', '849[EOS][PAD]', '138[EOS][PAD]', '1108[EOS]', '5269[EOS]', '128[EOS][PAD]', '537[EOS][PAD]', '639[EOS][PAD]', '579[EOS][PAD]', '1148[EOS]', '129[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.4667, 0.7333, 0.4667, 0.4667, 0.2000,\n",
            "        0.2000, 0.2000, 0.4667, 0.7333, 0.4667, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.8695, -0.8695, -0.8695, -0.8695,  0.5217,  1.9128,  0.5217,  0.5217,\n",
            "        -0.8695, -0.8695, -0.8695,  0.5217,  1.9128,  0.5217, -0.8695,  0.5217],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 88.40\n",
            "\n",
            "loss: 8.381903171539307e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['193[EOS][PAD]', '992[EOS][PAD]', '312[EOS][PAD]', '285[EOS]0', '300[EOS][PAD]', '3525[EOS]', '1937[EOS]', '324[EOS][PAD]', '103[EOS][EOS]', '216[EOS][PAD]', '1215[PAD]', '248[EOS][PAD]', '9717[EOS]', '116[EOS][PAD]', '1147[EOS]', '1843[EOS]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.4667, 0.2000, 0.4667, 0.4000, 0.2000, 0.7333, 0.0000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3912, -0.3912,  1.1736, -0.3912,  1.1736,  0.7824, -0.3912,  2.7385,\n",
            "        -1.5648, -0.3912, -0.3912, -0.3912, -0.3912, -0.3912, -0.3912, -0.3912],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 88.04\n",
            "\n",
            "loss: 1.0477378964424133e-09 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['698[EOS][PAD]', '5596[EOS]', '1189[EOS]', '1[PAD]0[EOS][PAD]', '115[EOS][PAD]', '8269[EOS]', '609[EOS][PAD]', '11195', '1133[EOS]', '518[EOS][PAD]', '1509[EOS]', '601[EOS]9', '1127[EOS]', '1146[EOS]', '598[EOS][PAD]', '1179[EOS]'] \n",
            "reward: tensor([0.2000, 0.6000, 0.2000, 0.0000, 0.2000, 0.2000, 0.4667, 0.0000, 0.2000,\n",
            "        0.4667, 0.2000, 0.0000, 0.2000, 0.2000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.2117,  2.0460, -0.2117, -1.3405, -0.2117, -0.2117,  1.2934, -1.3405,\n",
            "        -0.2117,  1.2934, -0.2117, -1.3405, -0.2117, -0.2117,  1.2934, -0.2117],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 88.00\n",
            "\n",
            "loss: -4.4587068259716034e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['819[EOS][PAD]', '1093[EOS]', '142[EOS][PAD]', '8540[EOS]', '110[EOS][PAD]', '946[EOS][PAD]', '1600[EOS]', '1158[EOS]', '108[EOS][PAD]', '1347[EOS]', '1308[EOS]', '1048[EOS]', '10279', '927[EOS][PAD]', '195[EOS][PAD]', '1189[EOS]'] \n",
            "reward: tensor([0.4667, 0.4000, 0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333,\n",
            "        0.2000, 0.2000, 0.4000, 0.1600, 0.2000, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.0843,  0.6570, -0.6249,  0.6570, -0.6249, -0.6249, -0.6249, -0.6249,\n",
            "         2.7936, -0.6249, -0.6249,  0.6570, -0.8813, -0.6249, -0.6249,  0.6570],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 88.73\n",
            "\n",
            "loss: -2.561137080192566e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1298[EOS]', '1125[EOS]', '121[EOS][PAD]', '116[EOS]2', '12814', '1909[EOS]', '1016[EOS]', '1421[EOS]', '111[EOS][PAD]', '11759', '0008[EOS]', '1410[EOS]', '1[PAD]18[EOS]', '1117[EOS]', '1125[EOS]', '110[EOS][PAD]'] \n",
            "reward: tensor([0.8000, 0.4000, 0.6000, 0.2000, 0.3200, 0.6000, 0.4000, 0.4000, 0.4000,\n",
            "        0.1600, 0.6000, 0.4000, 0.1000, 0.4000, 0.4000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 2.0505, -0.1294,  0.9605, -1.2194, -0.5654,  0.9605, -0.1294, -0.1294,\n",
            "        -0.1294, -1.4374,  0.9605, -0.1294, -1.7644, -0.1294, -0.1294,  0.9605],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 539.69s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 88.91\n",
            "\n",
            "loss: -4.237517714500427e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['440[EOS][PAD]', '1148[EOS]', '530[EOS][PAD]', '629[EOS][PAD]', '458[EOS][PAD]', '4239[EOS]', '629[EOS][PAD]', '1176[EOS]', '440[EOS][EOS]', '1151[EOS]', '111[EOS][PAD]', '511[EOS][PAD]', '448[EOS][PAD]', '1154[EOS]', '017[EOS][PAD]', '6167[EOS]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.4667, 0.4667, 0.4667, 0.4000, 0.4667, 0.2000, 0.2667,\n",
            "        0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.1541, -0.8977,  1.1541,  1.1541,  1.1541,  0.6412,  1.1541, -0.8977,\n",
            "        -0.3847, -0.8977, -0.8977, -0.8977,  1.1541, -0.8977, -0.8977, -0.8977],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 88.33\n",
            "\n",
            "loss: -1.4901161193847656e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['416[EOS][EOS]', '195[EOS][PAD]', '38[EOS]1[PAD]', '448[EOS][PAD]', '286[EOS][EOS]', '418[EOS][PAD]', '1579[EOS]', '1176[EOS]', '40[EOS][PAD]0', '38[EOS][PAD]1', '811[EOS][PAD]', '1126[EOS]', '119[EOS][PAD]', '287[EOS][PAD]', '336[EOS][PAD]', '1255[EOS]'] \n",
            "reward: tensor([0.0000, 0.4667, 0.2667, 0.2000, 0.0000, 0.2000, 0.2000, 0.2000, 0.0000,\n",
            "        0.1000, 0.2000, 0.2000, 0.2000, 0.2000, 0.4667, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.2904,  1.4624,  0.2826, -0.1106, -1.2904, -0.1106, -0.1106, -0.1106,\n",
            "        -1.2904, -0.7005, -0.1106, -0.1106, -0.1106, -0.1106,  1.4624,  2.2489],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 85.20\n",
            "\n",
            "loss: -4.516914486885071e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['319[EOS][PAD]', '902[EOS][EOS]', '438[EOS][PAD]', '1101[EOS]', '590[EOS][PAD]', '499[EOS][PAD]', '691[EOS][PAD]', '409[EOS][PAD]', '419[EOS][PAD]', '604[EOS][PAD]', '1025[EOS]', '111[EOS][PAD]', '911[EOS][PAD]', '1119[EOS]', '5497[EOS]', '1108[EOS]'] \n",
            "reward: tensor([0.4667, 0.0000, 0.4667, 0.2000, 0.4667, 0.4667, 0.2000, 0.4667, 0.4667,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.6000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.9167, -1.8582,  0.9167, -0.6690,  0.9167,  0.9167, -0.6690,  0.9167,\n",
            "         0.9167, -0.6690, -0.6690, -0.6690, -0.6690, -0.6690,  1.7096, -0.6690],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 84.33\n",
            "\n",
            "loss: -9.313225746154785e-09 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['7097[EOS]', '736[EOS]6', '1498[EOS]', '144[EOS][PAD]', '836[EOS][PAD]', '8408[EOS]', '1741[EOS]', '075[EOS][PAD]', '7519[EOS]', '137[EOS][PAD]', '697[EOS][PAD]', '1479[EOS]', '8666[EOS]', '916[EOS][PAD]', '7895[EOS]', '84[EOS][PAD][PAD]'] \n",
            "reward: tensor([0.4000, 0.0000, 0.2000, 0.2000, 0.4667, 0.4000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.1022, -2.0098, -0.4538, -0.4538,  1.6208,  1.1022, -0.4538, -0.4538,\n",
            "        -0.4538, -0.4538, -0.4538, -0.4538,  1.1022, -0.4538, -0.4538,  1.6208],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.99\n",
            "\n",
            "loss: -4.6566128730773926e-09 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1145[EOS]', '1140[EOS]', '129[EOS][PAD]', '11567', '1114[PAD]', '1118[EOS]', '142[EOS]9', '111[EOS]9', '1139[EOS]', '13969', '1108[EOS]', '1108[EOS]', '1115[EOS]', '1061[EOS]', '12703', '11104'] \n",
            "reward: tensor([0.4000, 0.4000, 0.6000, 0.1600, 0.2000, 0.6000, 0.2000, 0.2000, 0.4000,\n",
            "        0.1600, 0.8000, 0.8000, 0.4000, 0.4000, 0.3200, 0.1600],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.0580,  0.0580,  0.9860, -1.0556, -0.8700,  0.9860, -0.8700, -0.8700,\n",
            "         0.0580, -1.0556,  1.9139,  1.9139,  0.0580,  0.0580, -0.3132, -1.0556],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 525.18s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 84.80\n",
            "\n",
            "loss: 6.984919309616089e-09 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['523[EOS][PAD]', '111[EOS][PAD]', '188[EOS][PAD]', '1110[EOS]', '1104[EOS]', '437[EOS][PAD]', '424[EOS][PAD]', '712[EOS][PAD]', '1130[EOS]', '12278', '54[EOS][PAD][PAD]', '123[EOS][PAD]', '637[EOS][PAD]', '1147[EOS]', '152[EOS][PAD]', '408[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.7333, 0.4667, 0.2000, 0.2000,\n",
            "        0.0000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4056, -0.4056, -0.4056, -0.4056, -0.4056,  2.6481,  1.1213, -0.4056,\n",
            "        -0.4056, -1.5507, -0.4056, -0.4056,  1.1213, -0.4056, -0.4056,  1.1213],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.57\n",
            "\n",
            "loss: -6.28642737865448e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['1148[EOS]', '91[EOS][PAD][PAD]', '915[EOS][PAD]', '2315[EOS]', '468[EOS][PAD]', '11155', '278[EOS][PAD]', '3965[EOS]', '1236[EOS]', '244[EOS][PAD]', '4167[EOS]', '402[EOS][PAD]', '431[EOS][PAD]', '1277[EOS]', '000[EOS][PAD]', '306[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.0000, 0.2000, 0.4000, 0.4000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4538, -0.4538,  1.6208, -0.4538, -0.4538, -2.0098, -0.4538,  1.1022,\n",
            "         1.1022, -0.4538, -0.4538, -0.4538, -0.4538,  1.1022, -0.4538,  1.6208],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 84.41\n",
            "\n",
            "loss: -5.2386894822120667e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['1288[EOS]', '5369[EOS]', '5108[EOS]', '1897[EOS]', '608[EOS][PAD]', '390[EOS][PAD]', '182[EOS][PAD]', '102[EOS][PAD]', '1275[PAD]', '5778[EOS]', '1068[EOS]', '1187[EOS]', '113[EOS][EOS]', '1496[EOS]', '621[EOS][PAD]', '9232[EOS]'] \n",
            "reward: tensor([0.2000, 0.6000, 0.4000, 0.4000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000,\n",
            "        0.4000, 0.2000, 0.2000, 0.0000, 0.4000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3227,  2.2591,  0.9682,  0.9682, -0.3227, -0.3227, -0.3227, -0.3227,\n",
            "        -1.6136,  0.9682, -0.3227, -0.3227, -1.6136,  0.9682, -0.3227, -0.3227],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 84.43\n",
            "\n",
            "loss: -4.516914486885071e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['170[EOS]1', '140[EOS][PAD]', '11995', '407[EOS][PAD]', '118[EOS][PAD]', '419[EOS][PAD]', '1002[EOS]', '738[EOS][EOS]', '670[EOS][PAD]', '116[EOS][PAD]', '9072[EOS]', '705[EOS][PAD]', '1148[EOS]', '1102[EOS]', '154[EOS][PAD]', '1385[EOS]'] \n",
            "reward: tensor([0.0000, 0.2000, 0.0000, 0.4667, 0.4667, 0.2000, 0.4000, 0.2667, 0.2000,\n",
            "        0.2000, 0.4000, 0.4667, 0.2000, 0.2000, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.7540e+00, -4.3850e-01, -1.7540e+00,  1.3155e+00,  1.3155e+00,\n",
            "        -4.3850e-01,  8.7700e-01,  1.9602e-07, -4.3850e-01, -4.3850e-01,\n",
            "         8.7700e-01,  1.3155e+00, -4.3850e-01, -4.3850e-01, -4.3850e-01,\n",
            "         8.7700e-01], device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.44\n",
            "\n",
            "loss: -1.6530975699424744e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['110[EOS][EOS]', '1174[EOS]', '1294[EOS]', '139[EOS][PAD]', '1285[EOS]', '1101[EOS]', '1019[EOS]', '10018', '102[EOS][PAD]', '1189[EOS]', '1009[EOS]', '11890', '159[EOS][PAD]', '106[EOS][PAD]', '1102[EOS]', '1848[EOS]'] \n",
            "reward: tensor([0.4000, 0.4000, 0.6000, 0.4000, 0.6000, 0.6000, 0.4000, 0.3200, 0.4000,\n",
            "        0.4000, 0.6000, 0.1600, 0.4000, 0.4000, 0.6000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4213, -0.4213,  1.1107, -0.4213,  1.1107,  1.1107, -0.4213, -1.0341,\n",
            "        -0.4213, -0.4213,  1.1107, -2.2597, -0.4213, -0.4213,  1.1107,  1.1107],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 514.86s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 84.00\n",
            "\n",
            "loss: -5.7159923017024994e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['33[EOS][PAD]1', '421[EOS][PAD]', '442[EOS][PAD]', '0236[EOS]', '621[EOS][PAD]', '117[EOS]1', '5007[EOS]', '159[EOS][PAD]', '616[EOS][PAD]', '418[EOS][PAD]', '4187[EOS]', '116[EOS][PAD]', '515[EOS][PAD]', '492[EOS][EOS]', '1115[EOS]', '5393[EOS]'] \n",
            "reward: tensor([0.1000, 0.4667, 0.4667, 0.2000, 0.2000, 0.0000, 0.2000, 0.4667, 0.2000,\n",
            "        0.4667, 0.4000, 0.2000, 0.2000, 0.2667, 0.2000, 0.6000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.1460,  1.0704,  1.0704, -0.5415, -0.5415, -1.7504, -0.5415,  1.0704,\n",
            "        -0.5415,  1.0704,  0.6674, -0.5415, -0.5415, -0.1385, -0.5415,  1.8764],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 82.83\n",
            "\n",
            "loss: 4.423782229423523e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['1181[EOS]', '346[EOS][PAD]', '380[EOS][PAD]', '716[EOS][PAD]', '28767', '475[EOS][PAD]', '115[EOS][PAD]', '4147[EOS]', '90[EOS]1[EOS]', '2684[EOS]', '487[EOS][PAD]', '318[EOS][PAD]', '457[EOS][PAD]', '5167[EOS]', '927[EOS][PAD]', '310[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.4667, 0.2000, 0.0000, 0.4667, 0.4667, 0.2000, 0.0000,\n",
            "        0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.4667, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5332,  1.0179,  1.0179, -0.5332, -1.6965,  1.0179,  1.0179, -0.5332,\n",
            "        -1.6965, -0.5332, -0.5332,  1.0179, -0.5332, -0.5332,  1.0179,  1.0179],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 82.80\n",
            "\n",
            "loss: -4.237517714500427e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['4099[EOS]', '618[EOS][PAD]', '402[EOS][PAD]', '1119[EOS]', '099[EOS][PAD]', '539[EOS][PAD]', '120[EOS][PAD]', '1197[EOS]', '691[EOS][PAD]', '1139[PAD]', '1174[EOS]', '589[EOS][PAD]', '6001[EOS]', '13978', '416[EOS][PAD]', '688[EOS][PAD]'] \n",
            "reward: tensor([0.4000, 0.2000, 0.2000, 0.2000, 0.4667, 1.0000, 0.2000, 0.4000, 0.2000,\n",
            "        0.0000, 0.2000, 0.7333, 0.2000, 0.3200, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.3267, -0.4900, -0.4900, -0.4900,  0.5989,  2.7767, -0.4900,  0.3267,\n",
            "        -0.4900, -1.3067, -0.4900,  1.6878, -0.4900,  0.0000, -0.4900, -0.4900],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 82.85\n",
            "\n",
            "loss: -1.6065314412117004e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['1149[EOS]', '778[EOS][PAD]', '1721[PAD]', '150[PAD][PAD]', '993[EOS][PAD]', '1069[EOS]', '1160[EOS]', '6328[EOS]', '766[EOS][EOS]', '1177[EOS]', '718[EOS][PAD]', '6037[EOS]', '7047[EOS]', '1064[EOS]', '181[EOS][PAD]', '1[PAD]47[EOS]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.0000, 0.0000, 0.2000, 0.4000, 0.2000, 0.2000, 0.0000,\n",
            "        0.2000, 0.4667, 0.4000, 0.4000, 0.4000, 0.2000, 0.0000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.1936,  1.3555, -1.3555, -1.3555, -0.1936,  0.9682, -0.1936, -0.1936,\n",
            "        -1.3555, -0.1936,  1.3555,  0.9682,  0.9682,  0.9682, -0.1936, -1.3555],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 82.20\n",
            "\n",
            "loss: 1.210719347000122e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1190[EOS]', '1128[EOS]', '1018[EOS]', '1118[EOS]', '109[EOS][EOS]', '1005[EOS]', '1103[EOS]', '1111[EOS]', '13995', '110[EOS][EOS]', '140[EOS][PAD]', '11098', '1199[EOS]', '1123[EOS]', '1284[EOS]', '1218[EOS]'] \n",
            "reward: tensor([0.4000, 0.6000, 0.6000, 0.6000, 0.2000, 0.6000, 0.6000, 0.4000, 0.1600,\n",
            "        0.4000, 0.6000, 0.3200, 0.4000, 0.4000, 0.6000, 0.8000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.4662,  0.6993,  0.6993,  0.6993, -1.6318,  0.6993,  0.6993, -0.4662,\n",
            "        -1.8649, -0.4662,  0.6993, -0.9325, -0.4662, -0.4662,  0.6993,  1.8649],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 506.46s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 82.57\n",
            "\n",
            "loss: -5.9138983488082886e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['510[EOS][PAD]', '4269[EOS]', '1109[EOS]', '1114[EOS]', '311[EOS][PAD]', '491[EOS][PAD]', '1061[EOS]', '1334[EOS]', '1147[EOS]', '1138[EOS]', '6969[EOS]', '110[EOS][PAD]', '4199[EOS]', '538[EOS][PAD]', '1187[EOS]', '1178[EOS]'] \n",
            "reward: tensor([0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.4000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.6000, 0.4667, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.6198,  0.8677, -0.6198, -0.6198, -0.6198,  1.3636, -0.6198,  0.8677,\n",
            "        -0.6198, -0.6198, -0.6198, -0.6198,  2.3553,  1.3636, -0.6198, -0.6198],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 82.92\n",
            "\n",
            "loss: 1.210719347000122e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['319[EOS][PAD]', '136[EOS][PAD]', '2176[EOS]', '113[EOS][PAD]', '819[EOS][PAD]', '441[EOS][PAD]', '387[EOS][PAD]', '485[EOS][PAD]', '108[EOS][EOS]', '174[EOS][PAD]', '216[EOS][PAD]', '226[EOS][EOS]', '196[EOS][PAD]', '113[EOS][PAD]', '111[EOS][PAD]', '112[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.4667, 0.4667, 0.0000,\n",
            "        0.2000, 0.2000, 0.2667, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.8169, -0.3365, -0.3365, -0.3365, -0.3365, -0.3365,  1.8169,  1.8169,\n",
            "        -1.9515, -0.3365, -0.3365,  0.2019, -0.3365, -0.3365, -0.3365, -0.3365],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 82.73\n",
            "\n",
            "loss: 5.122274160385132e-09 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['5375[EOS]', '730[EOS][PAD]', '111[EOS][PAD]', '635[EOS][PAD]', '111[EOS][PAD]', '593[EOS][PAD]', '898[EOS][PAD]', '1138[EOS]', '1195[EOS]', '1189[PAD]', '689[EOS][PAD]', '529[EOS][PAD]', '1004[EOS]', '407[EOS][PAD]', '110[EOS][PAD]', '119[EOS][PAD]'] \n",
            "reward: tensor([0.6000, 0.4667, 0.2000, 0.4667, 0.2000, 0.4667, 0.2000, 0.2000, 0.4000,\n",
            "        0.0000, 0.4667, 0.7333, 0.2000, 0.2000, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.3383,  0.6475, -0.7339,  0.6475, -0.7339,  0.6475, -0.7339, -0.7339,\n",
            "         0.3022, -1.7700,  0.6475,  2.0290, -0.7339, -0.7339, -0.7339,  0.6475],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 84.05\n",
            "\n",
            "loss: -1.909211277961731e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['819[EOS][PAD]', '147[EOS][PAD]', '1168[EOS]', '1975[EOS]', '1208[EOS]', '7702[EOS]', '8247[EOS]', '739[EOS][PAD]', '1057[EOS]', '1016[EOS]', '1832[EOS]', '110[EOS][PAD]', '800[EOS][PAD]', '782[EOS][PAD]', '928[EOS][EOS]', '110[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.4000, 0.2000, 0.4000,\n",
            "        0.4000, 0.2000, 0.2000, 0.7333, 0.2000, 0.2667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.1529, -0.6039, -0.6039, -0.6039, -0.6039, -0.6039,  0.7137, -0.6039,\n",
            "         0.7137,  0.7137, -0.6039, -0.6039,  2.9097, -0.6039, -0.1647, -0.6039],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 83.52\n",
            "\n",
            "loss: -1.257285475730896e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1937[EOS]', '1394[EOS]', '110[EOS][PAD]', '1199[EOS]', '1183[EOS]', '1149[EOS]', '1121[EOS]', '0735[EOS]', '16107', '11148', '1118[EOS]', '121[EOS][PAD]', '139[EOS][PAD]', '1263[EOS]', '1134[EOS]', '1116[EOS]'] \n",
            "reward: tensor([0.4000, 0.4000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.2000, 0.1600,\n",
            "        0.1600, 0.6000, 0.6000, 0.4000, 0.6000, 0.4000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.0518, -0.0518,  1.3298, -0.0518, -0.0518, -0.0518, -0.0518, -1.4334,\n",
            "        -1.7097, -1.7097,  1.3298,  1.3298, -0.0518,  1.3298, -0.0518, -0.0518],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 509.31s | test accuracy  0.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 83.34\n",
            "\n",
            "loss: -2.537854015827179e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['109[EOS][PAD]', '10816', '939[EOS][EOS]', '1159[EOS]', '427[EOS][PAD]', '178[EOS][PAD]', '1198[EOS]', '514[EOS][PAD]', '15489', '10156', '11060', '1135[EOS]', '588[EOS][PAD]', '1571[EOS]', '[PAD]47[EOS]0', '196[EOS][EOS]'] \n",
            "reward: tensor([0.4667, 0.0000, 0.5333, 0.2000, 0.4667, 0.2000, 0.4000, 0.2000, 0.0000,\n",
            "        0.0000, 0.0000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.4599, -1.0175,  1.8138,  0.0442,  1.4599,  0.0442,  1.1059,  0.0442,\n",
            "        -1.0175, -1.0175, -1.0175,  0.0442,  0.0442,  0.0442, -1.0175, -1.0175],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.46\n",
            "\n",
            "loss: -1.816079020500183e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['128[EOS][PAD]', '4964[EOS]', '328[EOS][PAD]', '428[EOS][PAD]', '318[EOS][PAD]', '1477[EOS]', '210[EOS][PAD]', '4838[EOS]', '214[EOS][PAD]', '4125[EOS]', '425[EOS][PAD]', '928[EOS][PAD]', '381[EOS][PAD]', '1957[EOS]', '39961', '717[EOS][PAD]'] \n",
            "reward: tensor([0.4667, 0.2000, 0.7333, 0.4667, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.7333, 0.4667, 0.4667, 0.4000, 0.1600, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.5538, -0.8307,  1.9382,  0.5538,  0.5538, -0.8307, -0.8307, -0.8307,\n",
            "        -0.8307, -0.8307,  1.9382,  0.5538,  0.5538,  0.2077, -1.0383, -0.8307],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 86.64\n",
            "\n",
            "loss: -1.7462298274040222e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['417[EOS][PAD]', '5159[EOS]', '8919[EOS]', '1182[EOS]', '68[EOS][PAD][PAD]', '1129[EOS]', '1139[EOS]', '8987[EOS]', '1184[EOS]', '1149[EOS]', '619[EOS][PAD]', '109[EOS][PAD]', '1131[EOS]', '529[EOS][PAD]', '1077[EOS]', '598[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.2000, 0.4667, 0.4667, 0.2000, 0.7333, 0.2000, 0.4667],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5937,  0.6453, -0.5937, -0.5937, -0.5937, -0.5937, -0.5937, -0.5937,\n",
            "        -0.5937, -0.5937,  1.0583,  1.0583, -0.5937,  2.7102, -0.5937,  1.0583],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 86.40\n",
            "\n",
            "loss: 1.30385160446167e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['1580[EOS]', '1003[PAD]', '892[EOS][PAD]', '1[PAD]11[EOS]', '1618[EOS]', '160[EOS][PAD]', '1190[EOS]', '1460[EOS]', '131[EOS][PAD]', '187[EOS][EOS]', '157[EOS][PAD]', '1075[EOS]', '800[EOS][PAD]', '1107[EOS]', '1149[EOS]', '785[EOS][PAD]'] \n",
            "reward: tensor([0.4000, 0.2000, 0.4667, 0.0000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.0000, 0.2000, 0.4000, 0.7333, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 0.8424, -0.2808,  1.2168, -1.4040, -0.2808, -0.2808, -0.2808, -0.2808,\n",
            "        -0.2808, -1.4040, -0.2808,  0.8424,  2.7144, -0.2808, -0.2808, -0.2808],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.74\n",
            "\n",
            "loss: -2.2351741790771484e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1288[EOS]', '1499[EOS]', '110[EOS]9', '1148[EOS]', '1149[EOS]', '1159[EOS]', '1139[EOS]', '113[EOS]1', '1280[EOS]', '212[EOS][PAD]', '110[EOS][EOS]', '11124', '9260[EOS]', '1128[EOS]', '1119[EOS]', '1999[EOS]'] \n",
            "reward: tensor([0.8000, 0.4000, 0.4000, 0.6000, 0.4000, 0.4000, 0.4000, 0.2000, 0.6000,\n",
            "        0.2000, 0.4000, 0.1600, 0.4000, 0.6000, 0.4000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 2.2846, -0.1362, -0.1362,  1.0742, -0.1362, -0.1362, -0.1362, -1.3465,\n",
            "         1.0742, -1.3465, -0.1362, -1.5886, -0.1362,  1.0742, -0.1362, -0.1362],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 519.36s | test accuracy  0.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 84.57\n",
            "\n",
            "loss: -2.9802322387695312e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['419[EOS][PAD]', '489[EOS][PAD]', '3319[EOS]', '43[EOS][PAD]1', '108[EOS][PAD]', '1058[EOS]', '4535[EOS]', '649[EOS][PAD]', '449[EOS][PAD]', '501[EOS][PAD]', '529[EOS][PAD]', '549[EOS][PAD]', '6129[EOS]', '1012[EOS]', '118[EOS][PAD]', '1846[EOS]'] \n",
            "reward: tensor([0.7333, 0.7333, 0.4000, 0.2000, 0.2000, 0.2000, 0.4000, 0.4667, 0.7333,\n",
            "        0.2000, 0.4667, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([ 1.7125,  1.7125,  0.1195, -0.8364, -0.8364, -0.8364,  0.1195,  0.4381,\n",
            "         1.7125, -0.8364,  0.4381,  0.4381, -0.8364, -0.8364, -0.8364, -0.8364],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 84.34\n",
            "\n",
            "loss: -2.468004822731018e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['249[EOS][PAD]', '152[EOS][PAD]', '890[EOS][PAD]', '1236[EOS]', '38[EOS][PAD][PAD]', '197[EOS][PAD]', '842[EOS][PAD]', '194[EOS][EOS]', '337[EOS][EOS]', '514[EOS][PAD]', '91[EOS][PAD][PAD]', '317[EOS][PAD]', '424[EOS][PAD]', '318[EOS][PAD]', '444[EOS][PAD]', '412[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.4000, 0.4667, 0.2000, 0.2000, 0.0000, 0.2667,\n",
            "        0.2000, 0.2000, 0.4667, 0.4667, 0.4667, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5106, -0.5106, -0.5106,  0.9311,  1.4117, -0.5106, -0.5106, -1.9524,\n",
            "        -0.0300, -0.5106, -0.5106,  1.4117,  1.4117,  1.4117, -0.5106, -0.5106],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 84.92\n",
            "\n",
            "loss: -2.561137080192566e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['718[EOS][EOS]', '538[EOS][PAD]', '436[EOS][PAD]', '409[EOS][PAD]', '627[EOS][PAD]', '1970[EOS]', '694[EOS][PAD]', '1444[EOS]', '1124[EOS]', '538[EOS][PAD]', '615[EOS][PAD]', '499[EOS][PAD]', '1260[EOS]', '6888[EOS]', '118[EOS][PAD]', '1175[EOS]'] \n",
            "reward: tensor([0.0000, 0.7333, 0.4667, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
            "        0.7333, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.4627,  2.0638,  0.7814,  0.7814, -0.5009, -0.5009, -0.5009, -0.5009,\n",
            "        -0.5009,  2.0638, -0.5009,  0.7814, -0.5009, -0.5009, -0.5009, -0.5009],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 85.84\n",
            "\n",
            "loss: 1.1175870895385742e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['1673[EOS]', '827[EOS][PAD]', '111[EOS][PAD]', '150[EOS][PAD]', '120[EOS][EOS]', '1075[EOS]', '1[PAD]58[EOS]', '802[EOS][PAD]', '1168[EOS]', '712[EOS][PAD]', '799[EOS][PAD]', '769[EOS][PAD]', '717[EOS][PAD]', '1206[EOS]', '1156[EOS]', '1918[EOS]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.2000, 0.2000, 0.0000, 0.4000, 0.0000, 0.7333, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.2158,  1.3185, -0.2158, -0.2158, -1.3665,  0.9350, -1.3665,  2.8529,\n",
            "        -0.2158, -0.2158, -0.2158, -0.2158, -0.2158, -0.2158, -0.2158, -0.2158],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 84.48\n",
            "\n",
            "loss: -1.909211277961731e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['1431[EOS]', '11043', '110[EOS][EOS]', '1249[EOS]', '1110[EOS]', '1196[EOS]', '1485[EOS]', '1190[EOS]', '1009[EOS]', '12909', '110[EOS]4', '1194[EOS]', '1173[EOS]', '110[EOS]1', '1188[EOS]', '1197[EOS]'] \n",
            "reward: tensor([0.4000, 0.3200, 0.4000, 0.6000, 0.4000, 0.4000, 0.4000, 0.4000, 0.6000,\n",
            "        0.3200, 0.4000, 0.4000, 0.4000, 0.4000, 0.6000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3065, -1.1983, -0.3065,  1.9228, -0.3065, -0.3065, -0.3065, -0.3065,\n",
            "         1.9228, -1.1983, -0.3065, -0.3065, -0.3065, -0.3065,  1.9228, -0.3065],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 517.92s | test accuracy  0.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 82.43\n",
            "\n",
            "loss: 2.2118911147117615e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['1264[EOS]', '1174[EOS]', '113[EOS][PAD]', '5465[EOS]', '119[EOS][PAD]', '1484[EOS]', '140[EOS][PAD]', '1117[EOS]', '428[EOS][PAD]', '678[EOS][PAD]', '269[EOS][PAD]', '469[EOS][PAD]', '849[EOS][EOS]', '427[EOS][PAD]', '1418[EOS]', '539[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.4667,\n",
            "        0.2000, 0.4667, 0.7333, 0.2667, 0.4667, 0.2000, 0.7333],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.7146, -0.7146, -0.7146, -0.7146,  0.6713, -0.7146, -0.7146, -0.7146,\n",
            "         0.6713, -0.7146,  0.6713,  2.0572, -0.3681,  0.6713, -0.7146,  2.0572],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.62\n",
            "\n",
            "loss: -6.51925802230835e-09 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['219[EOS][PAD]', '324[EOS][EOS]', '1146[EOS]', '350[EOS][PAD]', '107[EOS]1', '1276[EOS]', '204[EOS][PAD]', '1958[EOS]', '1[PAD]362', '1056[EOS]', '1[PAD]0[EOS]0', '1023[EOS]', '1146[EOS]', '53[EOS][PAD][PAD]', '124[EOS][PAD]', '118[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.5333, 0.2000, 0.4667, 0.0000, 0.4000, 0.2000, 0.4000, 0.0000,\n",
            "        0.4000, 0.0000, 0.2000, 0.2000, 0.2000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.3140,  1.6182, -0.3140,  1.2318, -1.4733,  0.8453, -0.3140,  0.8453,\n",
            "        -1.4733,  0.8453, -1.4733, -0.3140, -0.3140, -0.3140,  1.2318, -0.3140],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 83.77\n",
            "\n",
            "loss: -8.102506399154663e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['426[EOS][PAD]', '109[EOS][PAD]', '1888[EOS]', '613[EOS][PAD]', '1029[EOS]', '101[EOS][PAD]', '539[EOS][PAD]', '1127[EOS]', '6488[EOS]', '1945[EOS]', '1019[EOS]', '198[EOS][PAD]', '1144[EOS]', '808[EOS][PAD]', '1189[EOS]', '1114[PAD]'] \n",
            "reward: tensor([0.2000, 0.4667, 0.2000, 0.2000, 0.2000, 0.2000, 1.0000, 0.2000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.2500,  0.9807, -0.2500, -0.2500, -0.2500, -0.2500,  3.4421, -0.2500,\n",
            "        -0.2500, -0.2500, -0.2500, -0.2500, -0.2500, -0.2500, -0.2500, -1.1730],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  2400/ 3600 batches | ms/batch 83.61\n",
            "\n",
            "loss: -3.818422555923462e-08 \n",
            "question: 609+199= \n",
            "answer 808 \n",
            "output: ['11388', '1495[EOS]', '1154[EOS]', '107[EOS][PAD]', '1387[EOS]', '4097[EOS]', '1[PAD]17[EOS]', '1081[EOS]', '1472[EOS]', '797[EOS][PAD]', '8770[EOS]', '196[EOS][PAD]', '152[EOS]1', '1[PAD]88[EOS]', '102[EOS][PAD]', '1477[EOS]'] \n",
            "reward: tensor([0.0000, 0.2000, 0.2000, 0.4667, 0.4000, 0.4000, 0.0000, 0.6000, 0.2000,\n",
            "        0.2000, 0.4000, 0.2000, 0.0000, 0.0000, 0.4667, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.2854, -0.2396, -0.2396,  1.1547,  0.8061,  0.8061, -1.2854,  1.8518,\n",
            "        -0.2396, -0.2396,  0.8061, -0.2396, -1.2854, -1.2854,  1.1547, -0.2396],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  3000/ 3600 batches | ms/batch 83.12\n",
            "\n",
            "loss: -5.168840289115906e-08 \n",
            "question: 822+386= \n",
            "answer 1208 \n",
            "output: ['4359[EOS]', '1489[EOS]', '1113[EOS]', '1156[EOS]', '126[EOS][PAD]', '1119[EOS]', '1221[EOS]', '1188[EOS]', '1012[EOS]', '12499', '1157[EOS]', '11439', '1108[EOS]', '1219[EOS]', '1128[EOS]', '1288[EOS]'] \n",
            "reward: tensor([0.2000, 0.4000, 0.4000, 0.4000, 0.6000, 0.4000, 0.6000, 0.6000, 0.4000,\n",
            "        0.3200, 0.4000, 0.1600, 0.8000, 0.6000, 0.6000, 0.8000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.5015, -0.4290, -0.4290, -0.4290,  0.6435, -0.4290,  0.6435,  0.6435,\n",
            "        -0.4290, -0.8580, -0.4290, -1.7159,  1.7159,  0.6435,  0.6435,  1.7159],\n",
            "       device='cuda:0') \n",
            "\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 510.48s | test accuracy  0.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "|   600/ 3600 batches | ms/batch 83.40\n",
            "\n",
            "loss: 2.468004822731018e-08 \n",
            "question: 297+142= \n",
            "answer 439 \n",
            "output: ['112[EOS][PAD]', '1194[EOS]', '994[EOS][EOS]', '408[EOS][PAD]', '1079[EOS]', '408[EOS][PAD]', '4119[EOS]', '112[EOS][PAD]', '4258[EOS]', '546[EOS][PAD]', '101[EOS][PAD]', '1109[EOS]', '68[EOS][PAD][PAD]', '449[EOS][PAD]', '1019[EOS]', '4057[EOS]'] \n",
            "reward: tensor([0.2000, 0.4000, 0.0000, 0.4667, 0.2000, 0.4667, 0.4000, 0.2000, 0.4000,\n",
            "        0.2000, 0.2000, 0.2000, 0.2000, 0.7333, 0.2000, 0.4000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.5993,  0.5514, -1.7501,  0.9350, -0.5993,  0.9350,  0.5514, -0.5993,\n",
            "         0.5514, -0.5993, -0.5993, -0.5993, -0.5993,  2.4693, -0.5993,  0.5514],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1200/ 3600 batches | ms/batch 83.84\n",
            "\n",
            "loss: -2.468004822731018e-08 \n",
            "question: 083+242= \n",
            "answer 325 \n",
            "output: ['457[EOS][PAD]', '1144[EOS]', '116[EOS][PAD]', '493[EOS][PAD]', '1806[EOS]', '314[EOS]1', '107[EOS][EOS]', '1246[EOS]', '494[EOS][PAD]', '417[EOS][PAD]', '110[EOS][PAD]', '1144[EOS]', '426[EOS][PAD]', '2167[EOS]', '7175[EOS]', '414[EOS][PAD]'] \n",
            "reward: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.4000, 0.2000,\n",
            "        0.2000, 0.2000, 0.2000, 0.4667, 0.2000, 0.2000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-0.1685, -0.1685, -0.1685, -0.1685, -0.1685, -0.1685, -2.1909,  1.8539,\n",
            "        -0.1685, -0.1685, -0.1685, -0.1685,  2.5280, -0.1685, -0.1685, -0.1685],\n",
            "       device='cuda:0') \n",
            "\n",
            "|  1800/ 3600 batches | ms/batch 84.50\n",
            "\n",
            "loss: 1.4435499906539917e-08 \n",
            "question: 277+262= \n",
            "answer 539 \n",
            "output: ['11865', '111[EOS][PAD]', '557[EOS][PAD]', '1139[EOS]', '11894', '1189[EOS]', '406[EOS][EOS]', '1181[EOS]', '546[EOS][PAD]', '11261', '847[EOS][PAD]', '509[EOS][PAD]', '591[EOS][PAD]', '1429[EOS]', '5699[EOS]', '6069[EOS]'] \n",
            "reward: tensor([0.0000, 0.2000, 0.4667, 0.2000, 0.0000, 0.2000, 0.0000, 0.2000, 0.4667,\n",
            "        0.0000, 0.2000, 0.7333, 0.4667, 0.2000, 0.6000, 0.2000],\n",
            "       device='cuda:0') \n",
            "advantage: tensor([-1.1451, -0.2586,  0.9235, -0.2586, -1.1451, -0.2586, -1.1451, -0.2586,\n",
            "         0.9235, -1.1451, -0.2586,  2.1055,  0.9235, -0.2586,  1.5145, -0.2586],\n",
            "       device='cuda:0') \n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_test_accuracy = None\n",
        "test_accuracy = evaluate()\n",
        "print('-' * 89)\n",
        "print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
        "print('-' * 89)\n",
        "\n",
        "# switch eval for train model (enables dropout)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    model_ref = TransformerModel(ntoken = ntokens,\n",
        "                         ninp = 128,\n",
        "                         nhead = 16,\n",
        "                         nhid = 64,\n",
        "                         nlayers = 8).to(device)\n",
        "    model_ref.load_state_dict(model.state_dict())\n",
        "    for param in model_ref.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "    epoch_start_time = time.time()\n",
        "    start_time = time.time()\n",
        "    for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
        "        # get a batch of prompts and answers\n",
        "        prompts, _, prompt_length, answers_length, questions, answers = get_batch(\"train\", i, batch_size)\n",
        "\n",
        "        model_old = TransformerModel(ntoken = ntokens,\n",
        "                         ninp = 128,\n",
        "                         nhead = 16,\n",
        "                         nhid = 64,\n",
        "                         nlayers = 8).to(device)\n",
        "        model_old.load_state_dict(model.state_dict())\n",
        "        for param in model_old.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        prompts = prompts.to(device) # (prompt_length, batch_size)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # generate samples for each prompt\n",
        "            outputs_old = generate(model_old,\n",
        "                                prompts,\n",
        "                                new_tokens = answers_length + 1,\n",
        "                                mode = \"sampling\",\n",
        "                                num_samples = num_samples,\n",
        "                                temperature = temperature)\n",
        "            # outputs.shape = (prompt_length + answers_length + 1, batch_size * num_samples)\n",
        "\n",
        "            log_probs_old = compute_log_probs(model_old, outputs_old, prompt_length) # (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "            log_probs_ref = compute_log_probs(model_ref, outputs_old, prompt_length) # (answers_length + 1, batch_size * num_samples, vocab_size)\n",
        "\n",
        "        text_outputs = [tokenizer.decode(outputs_old[prompt_length:, i].tolist())\n",
        "                        for i in range(outputs_old.size(1))] # (batch_size * num_samples, answers_length + 1)\n",
        "\n",
        "        responses_old = outputs_old[prompt_length:, :] # (answers_length + 1, batch_size * num_samples)\n",
        "\n",
        "        # compute rewards\n",
        "        rewards = compute_rewards(text_outputs, answers) # (batch_size * num_samples)\n",
        "\n",
        "        # # compute advantages\n",
        "        advantages = calculate_grpo_advantages(rewards) # (batch_size * num_samples)\n",
        "\n",
        "\n",
        "        for it in range(mu):\n",
        "            log_probs = compute_log_probs(model, outputs_old, prompt_length)\n",
        "\n",
        "            loss = compute_loss_grpo(advantages, log_probs, log_probs_old, log_probs_ref, responses_old, beta, eps)\n",
        "\n",
        "            # optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if i % log_interval == 0 and batch > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| {:5d}/{:5d} batches | ms/batch {:5.2f}'.format(batch, len(data_train) // batch_size, elapsed))\n",
        "            if verbose:\n",
        "                print(\"\\nloss:\", loss.item(),\n",
        "                    \"\\nquestion:\", questions[0],\n",
        "                  \"\\nanswer\", answers[0],\n",
        "                  \"\\noutput:\", text_outputs[:num_samples],\n",
        "                  \"\\nreward:\", rewards[:num_samples],\n",
        "                  \"\\nadvantage:\", advantages[:num_samples], \"\\n\")\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "    test_accuracy = evaluate()\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
        "    print('-' * 89)\n",
        "    if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
        "        with open(\"arithmetic_GRPO.pt\", 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_test_accuracy = test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ioeqJwLvrO6K",
      "metadata": {
        "id": "ioeqJwLvrO6K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
